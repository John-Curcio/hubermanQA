{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"GET YOUR OWN KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01. How Your Nervous System Works & Changes.md\n",
      "02. Master Your Sleep & Be More Alert When Awake.md\n",
      "03. Using Science to Optimize Sleep, Learning & Metabolism.md\n",
      "04. Find Your Temperature Minimum to Defeat Jetlag, Shift Work & Sleeplessness .md\n",
      "05. Understanding and Using Dreams to Learn and to Forget.md\n",
      "06. How to Focus to Change Your Brain.md\n",
      "07. Using Failures, Movement & Balance to Learn Faster.md\n",
      "08. Optimize Your Learning & Creativity with Science-based Tools.md\n",
      "09. Control Pain & Heal Faster with Your Brain.md\n",
      "10. Tools for Managing Stress & Anxiety.md\n",
      "11. How Foods and Nutrients Control Our Moods.md\n",
      "12. How to Increase Motivation & Drive.md\n",
      "13. The Science of Emotions & Relationships.md\n",
      "14. Biological Influences on Sex, Sex Differences & Preferences.md\n",
      "15. The Science of How to Optimize Testosterone & Estrogen.md\n",
      "16. How Our Hormones Control Our Hunger, Eating & Satiety.md\n",
      "17. How to Control Your Metabolism by Thyroid & Growth Hormone.md\n",
      "18. Using Cortisol & Adrenaline to Boost Our Energy & Immune System Function.md\n",
      "19. Supercharge Exercise Performance & Recover with Cooling.md\n",
      "20. How To Learn Skills Faster.md\n",
      "21. How to Lose Fat with Science-Based Tools.md\n",
      "22. Science of Muscle Growth, Increasing Strength & Muscular Recovery.md\n",
      "24. The Science of Vision, Eye Health & Seeing Better.md\n",
      "25. How Smell, Taste & Pheromone-Like Chemicals Control You.md\n",
      "27. The Science of Hearing, Balance & Accelerated Learning.md\n",
      "28. Maximizing Producitivity, Physical & Mental Health with Daily Tools.md\n",
      "30. How to Optimize Your Brain-Body Function & Health.md\n",
      "32. How to Control Your Sense of Pain & Pleasure.md\n",
      "34. Understanding & Conquering Depression.md\n",
      "37. ADHD & How Anyone Can Improve Their Focus.md\n",
      "39. Controlling Your Dopamine For Motivation, Focus & Satisfaction.md\n",
      "41. Effects of Fasting & Time Restricted Eating on Fat Loss & Health.md\n",
      "42. Nutrients For Brain Health & Performance.md\n",
      "44. Using Your Nervous System to Enhance Your Immune System.md\n",
      "46. Time Perception & Entrainment by Dopamine, Serotonin & Hormones.md\n",
      "47. The Science of Gratitude & How to Build a Gratitude Practice.md\n",
      "49. Erasing Fears & Traumas Based on the Modern Neuroscience of Fear.md\n",
      "51. Science of Social Bonding in Family, Friendship & Romantic Love.md\n"
     ]
    }
   ],
   "source": [
    "!ls md_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.161\n"
     ]
    }
   ],
   "source": [
    "from langchain import __version__\n",
    "print(__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.embeddings.cohere import CohereEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores.elastic_vector_search import ElasticVectorSearch\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2203 documents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import tiktoken\n",
    "import re\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "def count_tokens(text):\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "class TranscriptLoader(object):\n",
    "\n",
    "    def __init__(self, path, chunk_size=1000, \n",
    "                 chunk_overlap=None, model_name=\"gpt-3.5-turbo\"):\n",
    "        self.path = path\n",
    "        self.chunk_size = chunk_size\n",
    "        if chunk_overlap is None:\n",
    "            chunk_overlap = chunk_size // 2\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.model_name = model_name\n",
    "        self.markdown_text = None\n",
    "        self.texts = None\n",
    "        self.title = None\n",
    "        self.metadatas = None\n",
    "\n",
    "    def parse_text(self):\n",
    "        \"\"\"\n",
    "        Load the text from the markdown file, parse it into \n",
    "        individual chunks, and parse metadata for each chunk.\n",
    "        Return list of Documents.\n",
    "        \"\"\"\n",
    "        with open(self.path, 'r') as f:\n",
    "            text = f.read()\n",
    "        self.markdown_text = text\n",
    "        self.texts = re.findall(r'</summary>(.*?)</details>', \n",
    "                                self.markdown_text, re.DOTALL)\n",
    "        match = re.search(r'\\*\\*(.*?)\\*\\*', text)\n",
    "        if match:\n",
    "            self.title = match.group(1)\n",
    "        else:\n",
    "            self.title = \"\"\n",
    "        chunk_summaries = re.findall(r'<summary>(.*?)</summary>', \n",
    "                                     self.markdown_text, re.DOTALL)\n",
    "        self.metadatas = [{\n",
    "                            \"title\": self.title,\n",
    "                            \"summary\": summary,\n",
    "                            \"source\": f\"{self.title} {summary}\"\n",
    "                          }\n",
    "                          for summary in chunk_summaries]\n",
    "        splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=self.chunk_size,\n",
    "            chunk_overlap=self.chunk_size // 2,\n",
    "            length_function=count_tokens,\n",
    "        )\n",
    "        return splitter.create_documents(self.texts, self.metadatas)\n",
    "        \n",
    "class DocSearch(object):\n",
    "    \"\"\"\n",
    "    Given a path to a folder of markdown files, load the files,\n",
    "    parse them into chunks, and index them for search.\n",
    "    \"\"\"\n",
    "    def __init__(self, path, chunk_size=1000, db_persist_dir=None):\n",
    "        self.path = path\n",
    "        self.chunk_size = chunk_size\n",
    "        self.db_persist_dir = db_persist_dir\n",
    "        self.documents = []\n",
    "        self.docstore = None\n",
    "        self.vectorstore = None\n",
    "        self.embeddings = None\n",
    "        self.splitter = None\n",
    "        self.searcher = None\n",
    "\n",
    "    def load_documents(self):\n",
    "        \"\"\"\n",
    "        Load the documents from the markdown files.\n",
    "        \"\"\"\n",
    "        self.documents = []\n",
    "        for filename in os.listdir(self.path):\n",
    "            if filename.endswith(\".md\"):\n",
    "                loader = TranscriptLoader(os.path.join(self.path, filename))\n",
    "                loader.parse_text()\n",
    "                self.documents.extend(loader.parse_text())\n",
    "        print(f\"Loaded {len(self.documents)} documents.\")\n",
    "    \n",
    "    def index_documents(self):\n",
    "        \"\"\"\n",
    "        Index the documents for search.\n",
    "        \"\"\"\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        # try loading the persisted database from disk first\n",
    "        if self.db_persist_dir and os.path.exists(self.db_persist_dir):\n",
    "            self.db = Chroma(persist_directory=self.db_persist_dir,\n",
    "                             embedding_function=embeddings)\n",
    "            return\n",
    "        # otherwise, index the documents\n",
    "        if self.documents is None:\n",
    "            self.load_documents()\n",
    "        self.db = Chroma.from_documents(self.documents, embeddings, \n",
    "            persist_directory=self.db_persist_dir)\n",
    "        if self.db_persist_dir:\n",
    "            self.db.persist()\n",
    "\n",
    "    def search(self, query, k=4, search_type=\"mmr\"):\n",
    "        \"\"\"\n",
    "        Search the documents for the query.\n",
    "        Parameters:\n",
    "            query: str\n",
    "                The query to search for.\n",
    "            n: int\n",
    "                The number of results to return.\n",
    "            search_type: str\n",
    "                The type of search to perform. Options are:\n",
    "                    \"mmr\": Maximal Marginal Relevance\n",
    "                    \"similarity\": Similarity search\n",
    "        \"\"\"\n",
    "        if self.db is None:\n",
    "            self.index_documents()\n",
    "        return self.db.search(query, k=k, search_type=search_type)\n",
    "\n",
    "        \n",
    "# docsearch = DocSearch(\"md_transcripts\", db_persist_dir=\"db\")\n",
    "docsearch = DocSearch(\"md_transcripts\", chunk_size=480)\n",
    "docsearch.load_documents()\n",
    "docsearch.index_documents()\n",
    "# docsearch.search(\"What are some nootropics that would help me learn a language faster?\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11278\n"
     ]
    }
   ],
   "source": [
    "foo = docsearch.search(\"How would caffeine, alpha GPC, L-tyrosine, Adderall, and Modafinil\\\n",
    " affect my ability to learn a language?\", k=20)\n",
    "\n",
    "print(sum([count_tokens(doc.page_content) for doc in foo]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/llms/openai.py:169: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/llms/openai.py:687: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following extracted parts of a long document and a question, create a final answer with references (\"SOURCES\"). \n",
      "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
      "ALWAYS return a \"SOURCES\" part in your answer.\n",
      "\n",
      "QUESTION: Which state/country's law governs the interpretation of the contract?\n",
      "=========\n",
      "Content: This Agreement is governed by English law and the parties submit to the exclusive jurisdiction of the English courts in  relation to any dispute (contractual or non-contractual) concerning this Agreement save that either party may apply to any court for an  injunction or other relief to protect its Intellectual Property Rights.\n",
      "Source: 28-pl\n",
      "Content: No Waiver. Failure or delay in exercising any right or remedy under this Agreement shall not constitute a waiver of such (or any other)  right or remedy.\n",
      "\n",
      "11.7 Severability. The invalidity, illegality or unenforceability of any term (or part of a term) of this Agreement shall not affect the continuation  in force of the remainder of the term (if any) and this Agreement.\n",
      "\n",
      "11.8 No Agency. Except as expressly stated otherwise, nothing in this Agreement shall create an agency, partnership or joint venture of any  kind between the parties.\n",
      "\n",
      "11.9 No Third-Party Beneficiaries.\n",
      "Source: 30-pl\n",
      "Content: (b) if Google believes, in good faith, that the Distributor has violated or caused Google to violate any Anti-Bribery Laws (as  defined in Clause 8.5) or that such a violation is reasonably likely to occur,\n",
      "Source: 4-pl\n",
      "=========\n",
      "FINAL ANSWER: This Agreement is governed by English law.\n",
      "SOURCES: 28-pl\n",
      "\n",
      "QUESTION: What did the president say about Michael Jackson?\n",
      "=========\n",
      "Content: Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \n",
      "\n",
      "Last year COVID-19 kept us apart. This year we are finally together again. \n",
      "\n",
      "Tonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \n",
      "\n",
      "With a duty to one another to the American people to the Constitution. \n",
      "\n",
      "And with an unwavering resolve that freedom will always triumph over tyranny. \n",
      "\n",
      "Six days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \n",
      "\n",
      "He thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \n",
      "\n",
      "He met the Ukrainian people. \n",
      "\n",
      "From President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world. \n",
      "\n",
      "Groups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland.\n",
      "Source: 0-pl\n",
      "Content: And we won’t stop. \n",
      "\n",
      "We have lost so much to COVID-19. Time with one another. And worst of all, so much loss of life. \n",
      "\n",
      "Let’s use this moment to reset. Let’s stop looking at COVID-19 as a partisan dividing line and see it for what it is: A God-awful disease.  \n",
      "\n",
      "Let’s stop seeing each other as enemies, and start seeing each other for who we really are: Fellow Americans.  \n",
      "\n",
      "We can’t change how divided we’ve been. But we can change how we move forward—on COVID-19 and other issues we must face together. \n",
      "\n",
      "I recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera. \n",
      "\n",
      "They were responding to a 9-1-1 call when a man shot and killed them with a stolen gun. \n",
      "\n",
      "Officer Mora was 27 years old. \n",
      "\n",
      "Officer Rivera was 22. \n",
      "\n",
      "Both Dominican Americans who’d grown up on the same streets they later chose to patrol as police officers. \n",
      "\n",
      "I spoke with their families and told them that we are forever in debt for their sacrifice, and we will carry on their mission to restore the trust and safety every community deserves.\n",
      "Source: 24-pl\n",
      "Content: And a proud Ukrainian people, who have known 30 years  of independence, have repeatedly shown that they will not tolerate anyone who tries to take their country backwards.  \n",
      "\n",
      "To all Americans, I will be honest with you, as I’ve always promised. A Russian dictator, invading a foreign country, has costs around the world. \n",
      "\n",
      "And I’m taking robust action to make sure the pain of our sanctions  is targeted at Russia’s economy. And I will use every tool at our disposal to protect American businesses and consumers. \n",
      "\n",
      "Tonight, I can announce that the United States has worked with 30 other countries to release 60 Million barrels of oil from reserves around the world.  \n",
      "\n",
      "America will lead that effort, releasing 30 Million barrels from our own Strategic Petroleum Reserve. And we stand ready to do more if necessary, unified with our allies.  \n",
      "\n",
      "These steps will help blunt gas prices here at home. And I know the news about what’s happening can seem alarming. \n",
      "\n",
      "But I want you to know that we are going to be okay.\n",
      "Source: 5-pl\n",
      "Content: More support for patients and families. \n",
      "\n",
      "To get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health. \n",
      "\n",
      "It’s based on DARPA—the Defense Department project that led to the Internet, GPS, and so much more.  \n",
      "\n",
      "ARPA-H will have a singular purpose—to drive breakthroughs in cancer, Alzheimer’s, diabetes, and more. \n",
      "\n",
      "A unity agenda for the nation. \n",
      "\n",
      "We can do this. \n",
      "\n",
      "My fellow Americans—tonight , we have gathered in a sacred space—the citadel of our democracy. \n",
      "\n",
      "In this Capitol, generation after generation, Americans have debated great questions amid great strife, and have done great things. \n",
      "\n",
      "We have fought for freedom, expanded liberty, defeated totalitarianism and terror. \n",
      "\n",
      "And built the strongest, freest, and most prosperous nation the world has ever known. \n",
      "\n",
      "Now is the hour. \n",
      "\n",
      "Our moment of responsibility. \n",
      "\n",
      "Our test of resolve and conscience, of history itself. \n",
      "\n",
      "It is in this moment that our character is formed. Our purpose is found. Our future is forged. \n",
      "\n",
      "Well I know this nation.\n",
      "Source: 34-pl\n",
      "=========\n",
      "FINAL ANSWER: The president did not mention Michael Jackson.\n",
      "SOURCES:\n",
      "\n",
      "QUESTION: What are some nootropics that would help me learn a language faster? Please include an explanation for each one.\n",
      "=========\n",
      "Content: Which brings us to the next thing about learning and plasticity which is nootropics, AKA smart drugs. [sighs] This is a big topic that sigh was a sigh of concern about how to address nootropics in a thorough enough, but thoughtful enough way. Look, I have a lot of thoughts about nootropics. First of all, it means smart drugs, I believe. And I don't like that phrase because let's just take a step back and think about exercise. You just say, I want to be more physically fit. What does that mean? Does it mean I would ask for more specificity, I'd say, Do you want to be stronger? Okay, maybe you need to lift heavier objects progressively. Do you want more endurance very different protocol to access endurance. Do you want flexibility? Do you want explosiveness or suppleness? Huge range of things that we call physical fitness. Maybe you want all of those. If we were talking about emotional fitness we would say, well, inability to feel empathy but probably also to disengage from empathy because you don't want to be tethered to other people's emotions all the time. That's not healthy either. You would think about being able to access a range of emotions, but for some people their range into the sadness regime is really quite vast but their range into the happiness regime might be kind of limited. For other people who are in a manic state, it might be, they can access all that happy stuff but not the sadder stuff. So I'm speaking by way of analogy here. But if we say we're talking about cognitive and cognitive abilities we have to ask, okay, creativity, memory. We tend to associate intelligence with memory. And I think this goes back to like spelling bees or something, the ability to retain a lot of information and just regurgitate information which will get you some distance in some disciplines of life. But it won't allow you creative thinking, it's necessary for creative thinking. You need a knowledge base, right? You can't just look up everything on Google, despite what you know, certain educators or so-called educators say, you need a database so that you can have the raw materials with which to be creative. So necessary to have memory but not sufficient to be creative, right? The creative could have a poor memory for certain things but certainly not for everything. They can't have anterograde and retrograde amnesia. They'd be like the goldfish that every time around the tank,\n",
      "Source: Using Science to Optimize Sleep, Learning & Metabolism | Huberman Lab Podcast #3 (00:54:05) Smart Drugs\n",
      "\n",
      "Content: traditionally from caffeine stimulation. The acetylcholine stimulation traditionally comes from Coleen donors or alpha GPC, things of that sort. And then you would want to have some sort of off switch, because anything that's going to really stimulate your alertness, that then provides a crash. That crash is not a crash into the deep kind of restful slumber that you would want for learning, it's a crash into the kind of, let's just call it lopsided sleep, meaning it's deep sleep but it lacks certain spindles and other elements of the physiology sleep spindles, that really engage the learning process and the reconfiguration of synopsis. So right now, my stance on nootropics is that maybe, maybe for occasional use, provided it's safe for you, I'm not recommending it, but in general it tends to use more of a shotgun approach than is probably going to be useful for learning and memory in the long run. A lot of people ask about Modafinil or armodafinil which was designed for treatment of narcolepsy. So right there, it tells you it's a stimulant. And yes, there is evidence, it will improve learning memory. Modafinil is very expensive. Last time I checked our Modafinil I think is the recent released a generic version of this that's far less expensive. Most of these things look a lot like amphetamine and many of them have the potential for addiction or can be habit forming. But more importantly, a lot of those things also can create metabolic effects by disruption to insulin receptors and so forth. So you want to approach those with a strong sense of caution. Now, there are the milder things that act as nootropics that I mentioned, some of them like alpha GPC. Some people like Gingko. Gingko gives me vicious headaches, so I don't take it. So people really differ.\n",
      "Source: Using Science to Optimize Sleep, Learning & Metabolism | Huberman Lab Podcast #3 (00:54:05) Smart Drugs\n",
      "\n",
      "Content: it, you know I can't remember where it's at. I actually don't know that they've ever done that experiment by the way, but you know, so no disrespect to goldfish but you know, so you get the idea. You've got creativity, you have memory, you have the ability to task switch, right? You have the ability to strategy development, strategy implement. So the problem I have with the concept of a nootropic or a smart drug is it's not specific as to what cognitive algorithm you're trying to engage. We need more specificity. That said, there are elements to learning that we've discussed here before that are very concrete things like the ability to focus and put the blinders on to everything else that's happening in around you and in your head mainly, right? Distractions about things you should be doing, could be doing or might be doing and focus on what you need to do. And then that's required for triggering the acetylcholine neuromodulator that will then allow you to highlight the particular synopsis that will then later change in sleep. So no nootropic allows you to bypass the need for sleep in deep rest. That's important to understand. So I daydream about a day when people will be able to access compounds that are safe, that will allow them to learn better meaning, to access information, focus better, as well as to sleep better and activate the plasticity from the learning about. Right now most nootropics tend to bundle a bunch of things together. Most of them include some form of stimulant, caffeine. Episode two, I'll tell you more probably than you ever wanted to know about caffeine, adenosine and how that works. So refer there for how caffeine works. But stimulants will allow you to increase focus up to a particular point. If you have too little alertness in your system, you can't focus, too much however, you start to cliff and focus drifts, okay? So you can't just ingest more stimulant to be more focused. It doesn't work that way. Most nootropics also include things that increase or a desire to increase acetylcholine. Things like alpha GPC and other things of that sort. And indeed, there's some evidence that they can increase acetylcholine. I refer you again to examine.com the website to evaluate any supplements or compounds for their safety and their effects in humans and animals, free website as well as with links to studies. So we need the focus component. We need the alertness component. The alertness component comes from epinephrin,\n",
      "Source: Using Science to Optimize Sleep, Learning & Metabolism | Huberman Lab Podcast #3 (00:54:05) Smart Drugs\n",
      "\n",
      "Content: -\n",
      "  \n",
      "If you really need to learn conversational French to save your relationship, the chances are you're going to learn it. There are limits, of course, to the extent to which one can accentuate or accelerate plasticity. The ceiling on this is not infinite, although we don't know how high it goes. I think it's reasonable to say that if someone put a gun to my head and said, \"Learn conversational French in the next 120 seconds,\" that conversational French will be limited probably to just one word, probably the word oui or something like that. Because I can't stuff in all the knowledge all at once. I think that's the dream of brain-machine interface, that one will be able to download a chip into their hippocampus or cortex, or some other brain structure that would allow them to download conversational French. And someday we may get to that, that capability may come about. Right now, it does not exist, nor is there a specific pill or chemical that will allow you to download more information more quickly. This is the issue around nootropics I've talked about before. There are things that can increase focus, mainly things that increase acetylcholine and transmission through the nicotine system, things that can increase dopamine, things like L-tyrosine. Again, I'm not recommending these. You need to heed the warnings on those bottles, but they will increase these neurochemicals. And there are, of course, things that will increase epinephrin, things like caffeine, or some people, because of prescription, take Adderall. I'm, again, not suggesting people take any of these things. In fact, today I focused almost exclusively on behavioral tools and ways of structuring learning bouts that will allow you to access more plasticity regardless of age. And they center around things that I'm sure if you look around you you'll see evidence for, \"Oh, incremental learning is powerful,\" or, \"Oh, the vestibular system can open up opportunities for plasticity.\" I'm sure that the yogis out there all saying, \"Wait, this sounds exactly like yoga. We're supposed to push to an edge and do these inversions and do all those sorts of things.\" Well, I want to be clear, I never said anyone should do inversions. I said that the vestibular system is a valuable portal into some of these neurochemical states that favor plasticity.\n",
      "Source: Using Failures, Movement & Balance to Learn Faster | Huberman Lab Podcast #7 (1:19:25) Learning French and Other Things Faster\n",
      "=========\n",
      "FINAL ANSWER:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "There are several nootropics that may help with learning a language faster, including caffeine for increased focus, alpha GPC for increased acetylcholine, and L-tyrosine for increased dopamine. However, it is important to approach these with caution and to prioritize sleep and deep rest for optimal learning and plasticity. There is no specific pill or chemical that can allow for instant language learning, and it is important to focus on behavioral tools and structured learning bouts. \n",
      "\n",
      "Using Science to Optimize Sleep, Learning & Metabolism | Huberman Lab Podcast #3 (00:54:05) Smart Drugs, Using Failures, Movement & Balance to Learn Faster | Huberman Lab Podcast #7 (1:19:25) Learning French and Other Things Faster\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StdOutCallbackHandler\n",
    "\n",
    "class QA(object):\n",
    "\n",
    "    # def __init__(self, docsearch: DocSearch):\n",
    "    #     self.docsearch = docsearch\n",
    "    #     # create a chain of the following:\n",
    "    #     # 1. pull relevant documents from the database\n",
    "    #     # 2. preprocess them a little bit - ask to remove superfluous stuff\n",
    "    #     # not relevant to the question\n",
    "    #     # 3. sort them in order of most to least relevant\n",
    "    #     # 4. stuff them into the prompt of the GPT-3.5 model\n",
    "    #     assert False\n",
    "\n",
    "    # def answer(self, question, k=4):\n",
    "    #     # search the database for relevant documents\n",
    "    #     docs = self.docsearch.search(question, k=k)\n",
    "    #     # stuff them into the prompt of the GPT-3.5 model\n",
    "    #     # return the answer\n",
    "    #     assert False\n",
    "\n",
    "    def __init__(self, docsearch: DocSearch, model_name=\"gpt-3.5-turbo\",\n",
    "                 max_tokens_limit=4097):\n",
    "        self.docsearch = docsearch\n",
    "        self.chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "            OpenAI(\n",
    "            # ChatOpenAI(\n",
    "                # model_name=\"gpt-3.5-turbo\",\n",
    "                model_name=model_name,\n",
    "                # model_name=\"gpt-4-0314\",\n",
    "                temperature=0,\n",
    "            ), \n",
    "            # chain_type=\"map_reduce\",\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=docsearch.db.as_retriever(),\n",
    "            # reduce_k_below_max_tokens=False,\n",
    "            reduce_k_below_max_tokens=True,\n",
    "            max_tokens_limit=max_tokens_limit,\n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "    def answer(self, question):\n",
    "        return self.chain({\n",
    "            \"question\": question,\n",
    "        }, callbacks=[StdOutCallbackHandler()])\n",
    "    \n",
    "# qa = QA(docsearch, \"text-davinci-003\")\n",
    "qa = QA(docsearch, \"gpt-3.5-turbo\")\n",
    "# qa = QA(docsearch, \"davinci\", max_tokens_limit=2048)\n",
    "result = qa.answer(\"What are some nootropics that would \\\n",
    "help me learn a language faster? Please include an \\\n",
    "explanation for each one.\")\n",
    "print(result[\"answer\"])\n",
    "print(result[\"sources\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"traditionally from caffeine stimulation. The acetylcholine stimulation traditionally comes from Coleen donors or alpha GPC, things of that sort. And then you would want to have some sort of off switch, because anything that's going to really stimulate your alertness, that then provides a crash. That crash is not a crash into the deep kind of restful slumber that you would want for learning, it's a crash into the kind of, let's just call it lopsided sleep, meaning it's deep sleep but it lacks certain spindles and other elements of the physiology sleep spindles, that really engage the learning process and the reconfiguration of synopsis. So right now, my stance on nootropics is that maybe, maybe for occasional use, provided it's safe for you, I'm not recommending it, but in general it tends to use more of a shotgun approach than is probably going to be useful for learning and memory in the long run. A lot of people ask about Modafinil or armodafinil which was designed for treatment of narcolepsy. So right there, it tells you it's a stimulant. And yes, there is evidence, it will improve learning memory. Modafinil is very expensive. Last time I checked our Modafinil I think is the recent released a generic version of this that's far less expensive. Most of these things look a lot like amphetamine and many of them have the potential for addiction or can be habit forming. But more importantly, a lot of those things also can create metabolic effects by disruption to insulin receptors and so forth. So you want to approach those with a strong sense of caution. Now, there are the milder things that act as nootropics that I mentioned, some of them like alpha GPC. Some people like Gingko. Gingko gives me vicious headaches, so I don't take it. So people really differ.\", metadata={'title': 'Using Science to Optimize Sleep, Learning & Metabolism | Huberman Lab Podcast #3', 'summary': '(00:54:05) Smart Drugs', 'source': 'Using Science to Optimize Sleep, Learning & Metabolism | Huberman Lab Podcast #3 (00:54:05) Smart Drugs'}),\n",
       " Document(page_content=\"Now you may notice that I haven't talked much about acetylcholine. Acetylcholine is a neurotransmitter that at the neuron to muscle connections, the so called neuromuscular junctions is involved in generating muscular contractions of all kinds for all movements. Acetylcholine is also released from two sites in the brain. So a little bit of nomenclature here again, feel free to ignore the nomenclature, but there is a collection of neurons in your brain stem that send projections forward, kind of like a sprinkler system that's very diffuse to release acetylcholine and those neurons reside in an area or a structure that's called the pedunculopontine nucleus, the PPN and then there's a separate collection of neurons in the basal forebrain called unimaginatively nucleus basalis the nucleus at the base and they also hose the brain with acetylcholine, but in a much more specific way. So one is sort of like a sprinkler system and the other one is more like a fire hose to a particular location and those two sources of acetylcholine, collaborate to activate particular locations in the brain, and really bring about a tremendous degree of focus to whatever is happening at those particular synapses. So it could be a focus on visual information or auditory information, if you're listening closely to what I'm saying right now, and you just heard closely step out from the rest of my sentence, no doubt there was acetylcholine released at the sites in your brain where the neurons that represent your recognition of the word closely occurred, okay? So now you have an example and you have an understanding and hopefully a picture in your mind of how all this is working, not surprisingly then drugs that increase cholinergic or acetycholine transmission will increase focus and cognition. One such compound is so-called alpha GPC, which is a form of choline and increases acetycholine transmission dosages as high as 1200 milligrams per day, which has a very high dosage spread out, typically it's 300 or 400 milligrams spread out throughout the day have been shown to offset some of the effects of age-related cognitive decline, improved cognitive functioning people that don't have age-related cognitive decline that's a very high dose. Typically when people are using alpha-GPC to study or to enhance learning of any kind, they will take somewhere between 300 and 600 milligrams that's more typical. Again, you have to check with your doctor, you have to decide if the safety margins are appropriate for you obviously you'll want to check that out, but alpha-GPC is effective in creating more focused by way of this cholinergic system, It stimulates acetylcholine release from both of those locations, the PPN in the back of the brain and nucleus basalis in the front of the brain.\", metadata={'title': 'ADHD & How Anyone Can Improve Their Focus | Huberman Lab Podcast #37', 'summary': '(1:56:19) \\tAcetylcholine: Circuits Underlying Focus; Alpha-GPC', 'source': 'ADHD & How Anyone Can Improve Their Focus | Huberman Lab Podcast #37 (1:56:19) \\tAcetylcholine: Circuits Underlying Focus; Alpha-GPC'}),\n",
       " Document(page_content=\"that will allow them to learn better meaning, to access information, focus better, as well as to sleep better and activate the plasticity from the learning about. Right now most nootropics tend to bundle a bunch of things together. Most of them include some form of stimulant, caffeine. Episode two, I'll tell you more probably than you ever wanted to know about caffeine, adenosine and how that works. So refer there for how caffeine works. But stimulants will allow you to increase focus up to a particular point. If you have too little alertness in your system, you can't focus, too much however, you start to cliff and focus drifts, okay? So you can't just ingest more stimulant to be more focused. It doesn't work that way. Most nootropics also include things that increase or a desire to increase acetylcholine. Things like alpha GPC and other things of that sort. And indeed, there's some evidence that they can increase acetylcholine. I refer you again to examine.com the website to evaluate any supplements or compounds for their safety and their effects in humans and animals, free website as well as with links to studies. So we need the focus component. We need the alertness component. The alertness component comes from epinephrin, traditionally from caffeine stimulation. The acetylcholine stimulation traditionally comes from Coleen donors or alpha GPC, things of that sort. And then you would want to have some sort of off switch, because anything that's going to really stimulate your alertness, that then provides a crash. That crash is not a crash into the deep kind of restful slumber that you would want for learning, it's a crash into the kind of, let's just call it lopsided sleep, meaning it's deep sleep but it lacks certain spindles and other elements of the physiology sleep spindles, that really engage the learning process and the reconfiguration of synopsis. So right now, my stance on nootropics is that maybe, maybe for occasional use, provided it's safe for you, I'm not recommending it, but in general it tends to use more of a shotgun approach than is probably going to be useful for learning and memory in the long run. A lot of people ask about Modafinil or armodafinil which was designed for treatment of narcolepsy. So right there, it tells you it's a stimulant. And yes, there is evidence, it will improve learning memory. Modafinil is very expensive. Last time I checked our Modafinil I think is the\", metadata={'title': 'Using Science to Optimize Sleep, Learning & Metabolism | Huberman Lab Podcast #3', 'summary': '(00:54:05) Smart Drugs', 'source': 'Using Science to Optimize Sleep, Learning & Metabolism | Huberman Lab Podcast #3 (00:54:05) Smart Drugs'}),\n",
       " Document(page_content=\"-\\n  \\nMany of you are probably asking what can I take in order to accelerate skill learning? Well, the conditions are going to vary, but motivation is key. You have to show up to the training session motivated enough to focus your attention and to perform a lot of repetitions in the training sequence. That's just a prerequisite. There's no pill that's going to allow you to do fewer repetitions and extract more learning out of fewer repetitions. It's actually more a question of what are the conditions that you can create for yourself such that you can generate more repetitions per unit time. I think that's the right way to think about it. What are the conditions that you can create for yourself in your mind and in your body that are going to allow you to focus? And I've talked about focus and plasticity and motivation in previous episodes. Please see those episodes if you have questions about that. I've detailed a lot of tools in the underlying science. So for some people, it might be drinking a cup of coffee and getting hydrated before the training session. For some of you, it might be avoiding coffee because it makes you too jittery and your attention jumps all over the place. It's going to vary tremendously. There is no magic pill that's going to allow you to get more out of less, that's just not going to happen. It's simply not going to happen. You're not going to get more learning out of fewer repetitions or less time. However, there are a few compounds I think are worth mentioning because of their ability to improve the actual physical performance, the actual execution of certain types of movements. And some of these have also been shown to improve cognitive function, especially in older population. So I'd be remiss if I didn't at least mention them. I'm only going to mention one today in fact. The one that's particularly interesting and for which there really are a lot of data is alpha GPC and I'm going to attempt to pronounce what alpha GPC actually is. It's alpha glycerylphosphorylcholine. Alpha GPC, alpha glycerylphosphorylcholine. See, if I keep doing it over and over repetitions, alpha glycerylphosphorylcholine. There I made an error. Okay, so the point is that alpha GPC, which is at least in the United States is sold over the counter typically is taken in dosages of about 300 to 600 milligrams. That's a single dose or have been shown to do a number of things that for some of you might be beneficial. One is to enhance power output. So if you're engaging in something like Shotput throwing or resistance training or sprinting or something where you have to generate a lot of power, maybe you're doing rock climbing, but you're working on a particular aspect of your rock climbing that involves generating a lot of force, a lot of power. Well then in theory, alpha GPC could be beneficial to you. For the cognitive effects, the dosages are much higher up to 1200 milligrams daily divided into three doses of 400 milligrams is what the studies that I was able to find show or used. The effects on cognitive decline are described as notable. Notable, meaning several studies showed a significant but modest effect on in offsetting cognitive decline, in particular in older populations and some populations, even with some reported neuro degeneration. Power output was notable. How notable, what does that mean, notable? A study noted a 14% increase in power output. That's pretty substantial, 14%. And if you think about it, but it wasn't like a doubling or something of that sort. Believe it or not, the symptoms of Alzheimer's have been shown at least among the nutraceuticals of which alpha GPC is to significantly improve cognition in people with Alzheimer's. Now this episode, isn't about cognitive decline and longevity, we will talk about that, but this is a so-called another effect of alpha GPC. Fat oxidation is increased by alpha GPC, growth hormone release is promoted by alpha GPC although to a small degree. So as you can see, things like alpha GPC in particular when they are combined with low levels of caffeine can have these effects of improving power output, can improve growth hormone release, can improve fat oxidation. All these things in theory can support skill learning. But what they're really doing is they're adjusting the foundation upon which you are going to execute these many, many repetitions. The same thing would be said for caffeine itself. If that's something that motivates you and gets you out of a chair to actually do the physical training, then that's something that can perhaps improve or enhance the rate of skill learning and how well you retain those skills.\", metadata={'title': 'How to Learn Skills Faster | Huberman Lab Podcast #20', 'summary': '(01:39:00) Ingestible Compounds That Support Skill Learning: Motivation, Repetitions, Alpha-GPC', 'source': 'How to Learn Skills Faster | Huberman Lab Podcast #20 (01:39:00) Ingestible Compounds That Support Skill Learning: Motivation, Repetitions, Alpha-GPC'})]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch.search(\"The acetylcholine stimulation traditionally comes from Coleen donors or alpha GPC, things of that sort. And then you would want to have some sort of off switch, because anything that's going to really stimulate your alertness, that then provides a crash.\", search_type=\"similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('There are several nootropics that may help with learning a language faster, '\n",
      " 'including caffeine for increased focus, alpha GPC for increased '\n",
      " 'acetylcholine, and L-tyrosine for increased dopamine. However, it is '\n",
      " 'important to approach these with caution and to prioritize sleep and deep '\n",
      " 'rest for optimal learning and plasticity. There is no specific pill or '\n",
      " 'chemical that can allow for instant language learning, and it is important '\n",
      " 'to focus on behavioral tools and structured learning bouts. \\n')\n",
      "('Using Science to Optimize Sleep, Learning & Metabolism | Huberman Lab '\n",
      " 'Podcast #3 (00:54:05) Smart Drugs, Using Failures, Movement & Balance to '\n",
      " 'Learn Faster | Huberman Lab Podcast #7 (1:19:25) Learning French and Other '\n",
      " 'Things Faster')\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(result[\"answer\"])\n",
    "pprint.pprint(result[\"sources\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following extracted parts of a long document and a question, create a final answer with references (\"SOURCES\"). \n",
      "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
      "ALWAYS return a \"SOURCES\" part in your answer.\n",
      "\n",
      "QUESTION: Which state/country's law governs the interpretation of the contract?\n",
      "=========\n",
      "Content: This Agreement is governed by English law and the parties submit to the exclusive jurisdiction of the English courts in  relation to any dispute (contractual or non-contractual) concerning this Agreement save that either party may apply to any court for an  injunction or other relief to protect its Intellectual Property Rights.\n",
      "Source: 28-pl\n",
      "Content: No Waiver. Failure or delay in exercising any right or remedy under this Agreement shall not constitute a waiver of such (or any other)  right or remedy.\n",
      "\n",
      "11.7 Severability. The invalidity, illegality or unenforceability of any term (or part of a term) of this Agreement shall not affect the continuation  in force of the remainder of the term (if any) and this Agreement.\n",
      "\n",
      "11.8 No Agency. Except as expressly stated otherwise, nothing in this Agreement shall create an agency, partnership or joint venture of any  kind between the parties.\n",
      "\n",
      "11.9 No Third-Party Beneficiaries.\n",
      "Source: 30-pl\n",
      "Content: (b) if Google believes, in good faith, that the Distributor has violated or caused Google to violate any Anti-Bribery Laws (as  defined in Clause 8.5) or that such a violation is reasonably likely to occur,\n",
      "Source: 4-pl\n",
      "=========\n",
      "FINAL ANSWER: This Agreement is governed by English law.\n",
      "SOURCES: 28-pl\n",
      "\n",
      "QUESTION: What did the president say about Michael Jackson?\n",
      "=========\n",
      "Content: Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \n",
      "\n",
      "Last year COVID-19 kept us apart. This year we are finally together again. \n",
      "\n",
      "Tonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \n",
      "\n",
      "With a duty to one another to the American people to the Constitution. \n",
      "\n",
      "And with an unwavering resolve that freedom will always triumph over tyranny. \n",
      "\n",
      "Six days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \n",
      "\n",
      "He thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \n",
      "\n",
      "He met the Ukrainian people. \n",
      "\n",
      "From President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world. \n",
      "\n",
      "Groups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland.\n",
      "Source: 0-pl\n",
      "Content: And we won’t stop. \n",
      "\n",
      "We have lost so much to COVID-19. Time with one another. And worst of all, so much loss of life. \n",
      "\n",
      "Let’s use this moment to reset. Let’s stop looking at COVID-19 as a partisan dividing line and see it for what it is: A God-awful disease.  \n",
      "\n",
      "Let’s stop seeing each other as enemies, and start seeing each other for who we really are: Fellow Americans.  \n",
      "\n",
      "We can’t change how divided we’ve been. But we can change how we move forward—on COVID-19 and other issues we must face together. \n",
      "\n",
      "I recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera. \n",
      "\n",
      "They were responding to a 9-1-1 call when a man shot and killed them with a stolen gun. \n",
      "\n",
      "Officer Mora was 27 years old. \n",
      "\n",
      "Officer Rivera was 22. \n",
      "\n",
      "Both Dominican Americans who’d grown up on the same streets they later chose to patrol as police officers. \n",
      "\n",
      "I spoke with their families and told them that we are forever in debt for their sacrifice, and we will carry on their mission to restore the trust and safety every community deserves.\n",
      "Source: 24-pl\n",
      "Content: And a proud Ukrainian people, who have known 30 years  of independence, have repeatedly shown that they will not tolerate anyone who tries to take their country backwards.  \n",
      "\n",
      "To all Americans, I will be honest with you, as I’ve always promised. A Russian dictator, invading a foreign country, has costs around the world. \n",
      "\n",
      "And I’m taking robust action to make sure the pain of our sanctions  is targeted at Russia’s economy. And I will use every tool at our disposal to protect American businesses and consumers. \n",
      "\n",
      "Tonight, I can announce that the United States has worked with 30 other countries to release 60 Million barrels of oil from reserves around the world.  \n",
      "\n",
      "America will lead that effort, releasing 30 Million barrels from our own Strategic Petroleum Reserve. And we stand ready to do more if necessary, unified with our allies.  \n",
      "\n",
      "These steps will help blunt gas prices here at home. And I know the news about what’s happening can seem alarming. \n",
      "\n",
      "But I want you to know that we are going to be okay.\n",
      "Source: 5-pl\n",
      "Content: More support for patients and families. \n",
      "\n",
      "To get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health. \n",
      "\n",
      "It’s based on DARPA—the Defense Department project that led to the Internet, GPS, and so much more.  \n",
      "\n",
      "ARPA-H will have a singular purpose—to drive breakthroughs in cancer, Alzheimer’s, diabetes, and more. \n",
      "\n",
      "A unity agenda for the nation. \n",
      "\n",
      "We can do this. \n",
      "\n",
      "My fellow Americans—tonight , we have gathered in a sacred space—the citadel of our democracy. \n",
      "\n",
      "In this Capitol, generation after generation, Americans have debated great questions amid great strife, and have done great things. \n",
      "\n",
      "We have fought for freedom, expanded liberty, defeated totalitarianism and terror. \n",
      "\n",
      "And built the strongest, freest, and most prosperous nation the world has ever known. \n",
      "\n",
      "Now is the hour. \n",
      "\n",
      "Our moment of responsibility. \n",
      "\n",
      "Our test of resolve and conscience, of history itself. \n",
      "\n",
      "It is in this moment that our character is formed. Our purpose is found. Our future is forged. \n",
      "\n",
      "Well I know this nation.\n",
      "Source: 34-pl\n",
      "=========\n",
      "FINAL ANSWER: The president did not mention Michael Jackson.\n",
      "SOURCES:\n",
      "\n",
      "QUESTION: What is L-tyrosine, what does it do, and how does it work?\n",
      "=========\n",
      "Content: For that reason, many people have turned to the use of L-tyrosine. L-tyrosine is an amino acid precursor to l-DOPA. So it lies further up the dopamine synthesis pathway. And nowadays it's very common because all L-tyrosine is sold over the counter in the United States that people will take L-tyrosine as a way to get more energized alert and focused. Indeed, there are data that L-tyrosine will accomplish that. L-tyrosine is typically taken in capsule form or powder form anywhere from 500 to 750 to a 1000 milligrams. It is a potent stimulus for increasing dopamine. And the timescale for increasing dopamine is about 30 to 45 minutes after ingestion. Dopamine levels start to peak. The classic study that really nailed down the fact that tyrosine has this effect was published way back in 1983, Journal of Clinical Endocrinology and Metabolism that directly compared L-tyrosine supplementation with tryptophan ingestion on plasma dopamine and serotonin. Tryptophan being a precursor to serotonin. And indeed what they found is that ingestion of L-tyrosine can increase the amount of dopamine circulating in the blood and in the brain too, of course. The L-tyrosine ingestion induced dopamine increases within 45 minutes and they were short-lasting after about 30 minutes the effect had dissipated, meaning the levels of dopamine had dropped down to baseline. And even though they didn't look at levels of baseline dopamine past that time point, the expectation based on everything we know about dopamine biology is that it would then drop below baseline due to the depletion of the readily reservable pool of dopamine vesicles that we talked about way back at the beginning of this episode. The nice thing about this study is it does show specificity of effect because ingestion of tryptophan did not increase dopamine instead it increased serotonin. So there's really specificity of these pathways that rule out any placebo type effects. I'm not suggesting that anybody, everybody increase their dopamine levels by way of tyrosine or Macuna Pruriens. For those of you that are seeking to increase your dopamine levels without prescription drugs, those are the most direct route to that. Of course, if you have a pre-existing dopaminergic condition, so schizophrenia or psychosis of any kind, bipolar, anxiety, things like Macuna Pruriens and L-tyrosine will not be good for you. And if you don't, you should just understand and expect that it's going to lead to an increase in dopamine. You'll certainly feel an elevated state for some of you that might be agitating, for some of you that might be really pleasureful, and then you will feel a crash afterwards. How deep is that crash will really depend on your biology and where your dopamine baseline began. So I personally am not a fan of using things like Macuna Pruriens at all for myself for the reasons I mentioned earlier, just too intense and too much of a crash. I do use L-tyrosine from time to time for enhancing focus and motivation, but I want to emphasize from time to time. So I might use it once a week, occasionally twice a week, but I've never been one to take L-tyrosine regularly in order to focus or train or do any kind of mental work. I just don't want to rely on any exogenous substance in order to get my dopamine circuits activated. And I don't want to experience the drop in dopamine that inevitably occurs some period of time afterwards.\n",
      "Source: Controlling Your Dopamine For Motivation, Focus & Satisfaction | Huberman Lab Podcast #39 (2:01:45) \tTool 11 L-Tyrosine: Dosages, Duration of Effects & Specificity\n",
      "\n",
      "Content: Now, some people immediately ask, well should I supplement L-tyrosine? So let's just talk about that because that's gonna come up. Full disclosure, I sometimes take L-tyrosine. I'm not taking it right now, but I take it only occasionally, you can buy this in capsule form. It does increase kind of a mood and elevation and alertness. It is over the counter. You have to check with your doctor. I'm not responsible for your healthcare and I'm not a doctor, whether or not it's safe for you, people with preexisting hyper dopaminergic conditions like mania should probably not take L-tyrosine. The other thing about taking L-tyrosine is there is a crash, okay? It's not a massive crash if you take it at appropriate doses and it's right for you but it can produce a crash and a lethargy and a kind of brain fog after the next day or so. And so L-tyrosine however can be ingested through foods or through supplementation to increase dopamine levels. That's well-known, taken chronically however, it can disrupt those dopamine pathways. Now there are other drugs that will increase L-tyrosine and dopamine as well. But those are severe enough that they generally tend to have addictive properties. So things like methamphetamine, things like cocaine are terrible because they really ramp up the dopamine system so much that people really can't achieve dopamine release through any other mechanisms. But food and the ingestion of L-tyrosine has a profound effect on our levels of dopamine. It takes a little while but that really will impact level of mood. Certain antidepressants fall into the category of dopaminergic antidepressants. One of the most famous ones of course is Wellbutrin. Wellbutrin with developed because a lot of the other antidepressants tend to make people feel kind of lethargic or they had side effect profiles that people didn't like. So they developed this thing that, the generic name is different, but it's generally called Wellbutrin. Wellbutrin activates dopamine and epinephrin, which is a substrate of dopamine. And both of those are involved in motivation and alertness and effort. So you might say, wow, this sounds like a great drug. However, this drug, the side effect profile tends to be the things that are associated with elevated mood and alertness. So this isn't like taking some L-tyrosine. This isn't like eating some tyrosine rich foods. This is really a much greater release of\n",
      "Source: How Foods and Nutrients Control Our Moods | Huberman Lab Podcast #11 (00:34:04) Supplementing L-Tyrosine, Drugs of Abuse, Wellbutrin\n",
      "\n",
      "Content: There are two other over the counter compounds that are in active use out there for treatment of ADHD and in use for simply trying to improve focus and the first one is L-Tyrosine it's an amino acid that acts as a precursor to the neuromodulator dopamine and now knowing everything you know about dopamine, attention and the circuits involved, it should come as no surprise as to why people are exploring the use of L-tyrosine for that purpose. L-tyrosine does lead to increases in dopamine. They are fairly long lived and L-tyrosine can improve one's ability to focus, however, the dosaging can be very tricky to dial in. Sometimes it makes people feel too euphoric or too jittery or too alert that they are then unable to focus well. So the dosage ranges are huge, you see evidence for 100 milligrams all the way up to 1200 milligrams. It's something that really should be approached with caution, especially for people that have any kind of underlying psychiatric or mood disorder, because dysregulation of the dopamine system is central to many of the mood disorders such as depression, but also especially mania bipolar disorder, schizophrenia, things of that sort. So it's something that really should be approached with caution, nonetheless, in exploring what's out there and even some studies online that were done in either animal studies or human studies, it's clear that L-tyrosine is being explored for that purpose as is PEA and Phenethylamine, which is a essentially PEA, but some related compounds. So there's a whole class of dopaminergic or dopamine stimulating supplements that people are using to try and get their dopamine levels up and again, it's kind of a fine line between too little enough and too much. If you want to get the literature on those two compounds there, I will refer you to this great website at examine.com just as it sounds and you can put in L-tyrosine or PEA, and you can get the details on that. But I highly recommend also going to their section on ADHD to see how those particular comment OENs relate specifically to ADHD and cognitive focus.\n",
      "Source: ADHD & How Anyone Can Improve Their Focus | Huberman Lab Podcast #37 (1:59:04) \tL-Tyrosine, (PEA) Phenylethylamine \n",
      "\n",
      "Content: properties. So things like methamphetamine, things like cocaine are terrible because they really ramp up the dopamine system so much that people really can't achieve dopamine release through any other mechanisms. But food and the ingestion of L-tyrosine has a profound effect on our levels of dopamine. It takes a little while but that really will impact level of mood. Certain antidepressants fall into the category of dopaminergic antidepressants. One of the most famous ones of course is Wellbutrin. Wellbutrin with developed because a lot of the other antidepressants tend to make people feel kind of lethargic or they had side effect profiles that people didn't like. So they developed this thing that, the generic name is different, but it's generally called Wellbutrin. Wellbutrin activates dopamine and epinephrin, which is a substrate of dopamine. And both of those are involved in motivation and alertness and effort. So you might say, wow, this sounds like a great drug. However, this drug, the side effect profile tends to be the things that are associated with elevated mood and alertness. So this isn't like taking some L-tyrosine. This isn't like eating some tyrosine rich foods. This is really a much greater release of dopamine and epinephrin, and it increases things like anxiety, sweating, the pupils dilate. It has certain effects on, in particular people with epilepsy, it's been used somewhat successfully for smoking cessation, but again, it's not for everybody and I'm not here to encourage the use of these things. I'm just describing the biology and the rationale for why these drugs were developed. So let's back up a second. Let's just kind of take stock of where we're at. We have a brain body connection. There are many of them, but one of the main ones is the vagus nerve. The vagus collects information about a lot of things, breathing, heart rate stuff that's happening in the gut, et cetera, and gut by the way, includes the stomach and the intestines, sends that information up to the brain. The brain is using that information to decide one of two things, move toward something or move away. It can also pause, but essentially pausing is not moving toward. So that's the dopamine pathway and foods rich in L-tyrosine generally give us an elevated mood and make us want to do more of whatever it is that we happen to be doing as well as other things,\n",
      "Source: How Foods and Nutrients Control Our Moods | Huberman Lab Podcast #11 (00:34:04) Supplementing L-Tyrosine, Drugs of Abuse, Wellbutrin\n",
      "=========\n",
      "FINAL ANSWER:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "('L-tyrosine is an amino acid precursor to dopamine and is commonly used as an '\n",
      " 'over-the-counter supplement to increase energy, alertness, and focus. It can '\n",
      " 'be taken in capsule or powder form, with dosages ranging from 500 to 1000 '\n",
      " 'milligrams. L-tyrosine is a potent stimulus for increasing dopamine, with '\n",
      " 'levels peaking about 30 to 45 minutes after ingestion. It can be ingested '\n",
      " 'through foods or supplementation to increase dopamine levels, but chronic '\n",
      " 'use can disrupt dopamine pathways. Certain antidepressants, such as '\n",
      " 'Wellbutrin, fall into the category of dopaminergic antidepressants and '\n",
      " 'activate dopamine and epinephrine, which are involved in motivation, '\n",
      " 'alertness, and effort. However, these drugs have side effects such as '\n",
      " 'anxiety, sweating, and dilation of pupils. The dosaging of L-tyrosine can be '\n",
      " 'tricky to dial in, and it should be approached with caution, especially for '\n",
      " 'people with preexisting hyper dopaminergic conditions like mania. Sources: '\n",
      " 'Controlling Your Dopamine For Motivation, Focus & Satisfaction | Huberman '\n",
      " 'Lab Podcast #39 (2:01:45) Tool 11 L-Tyrosine: Dosages, Duration of Effects & '\n",
      " 'Specificity; How Foods and Nutrients Control Our Moods | Huberman Lab '\n",
      " 'Podcast #11 (00:34:04) Supplementing L-Tyrosine, Drugs of Abuse, Wellbutrin; '\n",
      " 'ADHD & How Anyone Can Improve Their Focus | Huberman Lab Podcast #37 '\n",
      " '(1:59:04) L-Tyrosine, (PEA) Phenylethylamine.')\n",
      "''\n"
     ]
    }
   ],
   "source": [
    "result = qa.answer(\"What is L-tyrosine, what does it do, and how does it work?\")\n",
    "# result = qa.answer(\"What is L-tyrosine?\")\n",
    "pprint.pprint(result[\"answer\"])\n",
    "pprint.pprint(result[\"sources\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following extracted parts of a long document and a question, create a final answer with references (\"SOURCES\"). \n",
      "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
      "ALWAYS return a \"SOURCES\" part in your answer.\n",
      "\n",
      "QUESTION: Which state/country's law governs the interpretation of the contract?\n",
      "=========\n",
      "Content: This Agreement is governed by English law and the parties submit to the exclusive jurisdiction of the English courts in  relation to any dispute (contractual or non-contractual) concerning this Agreement save that either party may apply to any court for an  injunction or other relief to protect its Intellectual Property Rights.\n",
      "Source: 28-pl\n",
      "Content: No Waiver. Failure or delay in exercising any right or remedy under this Agreement shall not constitute a waiver of such (or any other)  right or remedy.\n",
      "\n",
      "11.7 Severability. The invalidity, illegality or unenforceability of any term (or part of a term) of this Agreement shall not affect the continuation  in force of the remainder of the term (if any) and this Agreement.\n",
      "\n",
      "11.8 No Agency. Except as expressly stated otherwise, nothing in this Agreement shall create an agency, partnership or joint venture of any  kind between the parties.\n",
      "\n",
      "11.9 No Third-Party Beneficiaries.\n",
      "Source: 30-pl\n",
      "Content: (b) if Google believes, in good faith, that the Distributor has violated or caused Google to violate any Anti-Bribery Laws (as  defined in Clause 8.5) or that such a violation is reasonably likely to occur,\n",
      "Source: 4-pl\n",
      "=========\n",
      "FINAL ANSWER: This Agreement is governed by English law.\n",
      "SOURCES: 28-pl\n",
      "\n",
      "QUESTION: What did the president say about Michael Jackson?\n",
      "=========\n",
      "Content: Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \n",
      "\n",
      "Last year COVID-19 kept us apart. This year we are finally together again. \n",
      "\n",
      "Tonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \n",
      "\n",
      "With a duty to one another to the American people to the Constitution. \n",
      "\n",
      "And with an unwavering resolve that freedom will always triumph over tyranny. \n",
      "\n",
      "Six days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \n",
      "\n",
      "He thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \n",
      "\n",
      "He met the Ukrainian people. \n",
      "\n",
      "From President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world. \n",
      "\n",
      "Groups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland.\n",
      "Source: 0-pl\n",
      "Content: And we won’t stop. \n",
      "\n",
      "We have lost so much to COVID-19. Time with one another. And worst of all, so much loss of life. \n",
      "\n",
      "Let’s use this moment to reset. Let’s stop looking at COVID-19 as a partisan dividing line and see it for what it is: A God-awful disease.  \n",
      "\n",
      "Let’s stop seeing each other as enemies, and start seeing each other for who we really are: Fellow Americans.  \n",
      "\n",
      "We can’t change how divided we’ve been. But we can change how we move forward—on COVID-19 and other issues we must face together. \n",
      "\n",
      "I recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera. \n",
      "\n",
      "They were responding to a 9-1-1 call when a man shot and killed them with a stolen gun. \n",
      "\n",
      "Officer Mora was 27 years old. \n",
      "\n",
      "Officer Rivera was 22. \n",
      "\n",
      "Both Dominican Americans who’d grown up on the same streets they later chose to patrol as police officers. \n",
      "\n",
      "I spoke with their families and told them that we are forever in debt for their sacrifice, and we will carry on their mission to restore the trust and safety every community deserves.\n",
      "Source: 24-pl\n",
      "Content: And a proud Ukrainian people, who have known 30 years  of independence, have repeatedly shown that they will not tolerate anyone who tries to take their country backwards.  \n",
      "\n",
      "To all Americans, I will be honest with you, as I’ve always promised. A Russian dictator, invading a foreign country, has costs around the world. \n",
      "\n",
      "And I’m taking robust action to make sure the pain of our sanctions  is targeted at Russia’s economy. And I will use every tool at our disposal to protect American businesses and consumers. \n",
      "\n",
      "Tonight, I can announce that the United States has worked with 30 other countries to release 60 Million barrels of oil from reserves around the world.  \n",
      "\n",
      "America will lead that effort, releasing 30 Million barrels from our own Strategic Petroleum Reserve. And we stand ready to do more if necessary, unified with our allies.  \n",
      "\n",
      "These steps will help blunt gas prices here at home. And I know the news about what’s happening can seem alarming. \n",
      "\n",
      "But I want you to know that we are going to be okay.\n",
      "Source: 5-pl\n",
      "Content: More support for patients and families. \n",
      "\n",
      "To get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health. \n",
      "\n",
      "It’s based on DARPA—the Defense Department project that led to the Internet, GPS, and so much more.  \n",
      "\n",
      "ARPA-H will have a singular purpose—to drive breakthroughs in cancer, Alzheimer’s, diabetes, and more. \n",
      "\n",
      "A unity agenda for the nation. \n",
      "\n",
      "We can do this. \n",
      "\n",
      "My fellow Americans—tonight , we have gathered in a sacred space—the citadel of our democracy. \n",
      "\n",
      "In this Capitol, generation after generation, Americans have debated great questions amid great strife, and have done great things. \n",
      "\n",
      "We have fought for freedom, expanded liberty, defeated totalitarianism and terror. \n",
      "\n",
      "And built the strongest, freest, and most prosperous nation the world has ever known. \n",
      "\n",
      "Now is the hour. \n",
      "\n",
      "Our moment of responsibility. \n",
      "\n",
      "Our test of resolve and conscience, of history itself. \n",
      "\n",
      "It is in this moment that our character is formed. Our purpose is found. Our future is forged. \n",
      "\n",
      "Well I know this nation.\n",
      "Source: 34-pl\n",
      "=========\n",
      "FINAL ANSWER: The president did not mention Michael Jackson.\n",
      "SOURCES:\n",
      "\n",
      "QUESTION: Why is it so important to have sunlight exposure in the morning?\n",
      "=========\n",
      "Content: So if you are not feeling awake during the day and you're having trouble sleeping, get the sunlight exposure that we just talked about, but in addition to that, if you wanna become an early riser, for instance, and you wanna feel more awake during the early part of the day, by getting that light exposure and exercising early in the day, you will, after two or three days, you will naturally start to wake up earlier in the day, and that's because these clock mechanisms have shifted, it's like setting the clock earlier as opposed to delaying the clock, and that takes us to a somewhat complicated, but very important, aspect to all this, which is, what sets the clock and keeps it anchored? The main thing is that bright light early in the day, the other thing is sunset, when the sun is also at low solar angle, low, close to the horizon, by viewing sunlight at that time of day in the evening, or afternoon, depending on what time of year it is and where you are in the world, these melanopsin cells, these neurons in your eye, signal the central circadian clock that it's the end of the day, and there's a really nice study that was published last year, and I will put links to these references on a website not too long from now, there was a really nice study that showed that viewing sunlight around the time of the sunset, doesn't have to be just crossing the horizon, but circa sunset, within an hour or so of sunset, prevents some of the bad effects of light in preventing melatonin release later that same night, so let me repeat this, viewing light early in the day is key, viewing light later in the day when the sun is setting, or around that time, can help protect these mechanisms, your brain and body, against the negative effects of light later in the day, so let me talk about you would do that, you'd go view the sunset or you would go outside in the late afternoon or evening, again, if you safely can do that with sunglasses off, you will, if you need to wear sunglasses, fine, but it will take probably 100 to 1,000 times longer with dark sunglasses than if you take them off, again, if you wanna do this through a window at work, that's fine, but it'll take 50 times longer, so the best thing to do is just to get outside for a few minutes, anywhere from 2 to 10 minutes,\n",
      "Source: Master Your Sleep & Be More Alert When Awake | Huberman Lab Podcast #2 (00:42:00) The Power of Sunset\n",
      "\n",
      "Content: year, and I will put links to these references on a website not too long from now, there was a really nice study that showed that viewing sunlight around the time of the sunset, doesn't have to be just crossing the horizon, but circa sunset, within an hour or so of sunset, prevents some of the bad effects of light in preventing melatonin release later that same night, so let me repeat this, viewing light early in the day is key, viewing light later in the day when the sun is setting, or around that time, can help protect these mechanisms, your brain and body, against the negative effects of light later in the day, so let me talk about you would do that, you'd go view the sunset or you would go outside in the late afternoon or evening, again, if you safely can do that with sunglasses off, you will, if you need to wear sunglasses, fine, but it will take probably 100 to 1,000 times longer with dark sunglasses than if you take them off, again, if you wanna do this through a window at work, that's fine, but it'll take 50 times longer, so the best thing to do is just to get outside for a few minutes, anywhere from 2 to 10 minutes, also in the afternoon. Having those two signals arriving to your central clock that your body, your internal world, knows when it's morning and knows when it's evening, is tremendously powerful. Maybe think about it this way, every cell in your body needs glucose and energy, it needs, whether or not it gets that from meats or it gets it from ketones or it gets it from carbohydrates or fruit or vegetables, it doesn't matter, it is eventually converted into a certain form of energy that all your cells use, but you don't take glucose, you don't take bread or a steak or a nice orange and shove it in your ear, you put it in your mouth, it goes into your stomach, it's digested, and then that resource is distributed to all the cells of your body. Every cell in your body needs oxygen, and you don't put a hose you know, through your nostril or through your ear or through some other orifice in your body, you inhale air and it's then distributed via the lungs to the cells in your blood stream, and then it's distributed to all the organs of your body. Every cell and organ in your body needs light information, and the way to get that light information to all those\n",
      "Source: Master Your Sleep & Be More Alert When Awake | Huberman Lab Podcast #2 (00:42:00) The Power of Sunset\n",
      "\n",
      "Content: -\n",
      "  \n",
      "Okay, so let's think about why I'm making some of these recommendations because I think it can really empower you with the ability to change your behavior in terms of light viewing and other things, depending on time of year, depending on other lifestyle factors. The important point to understand is that early in the day, your central circadian clocks and all these mechanisms are looking for a lot of light. I mean, they don't have a mind of their own, but it needs a lot of light to trigger this daytime signal, alertness et cetera. And early in the day, but not in the middle of the day, you can sum or add photons. So there's this brief period of time early in the day, when the sun is low in the sky when your brain and body are expecting a morning wake up signal where let's say, it's not that bright outside. Someone sent me a picture or a little movie of their walk in England, and it was pretty overcast and they were using light meter and they said it's only about 700 lux or maybe even less. And I said, well, stay outside longer. But when you get inside, turn on the lights really bright and overhead lights in particular, because those will be best for stimulating these mechanisms. And that's because at least for the first few hours of the day, you can continue to some or add photon activation of the cells in the eye and the brain. In the middle of the day, once the sun is overhead, or even if you stay inside all morning, and then you're in the circadian dead zone, which sounds terrible and it is terrible. You doesn't matter if you get a ton of artificial light or even sunlight, you're not going to shift your circadian clock. You're not going to get that wake up signal. And then in the evening, you want to think about this whole system as being vulnerable to even a few photons of light because of their sensitivity to light really goes up at night. And I talked last time about how you can protect against that sensitivity by looking at the setting sun and watching the evening sun, even if it's not crossing the horizon around the time of sunset. And that's because it adjusts your retinal sensitivity and your melatonin pathway so that light is not as detrimental to melatonin at night.\n",
      "Source: Using Science to Optimize Sleep, Learning & Metabolism | Huberman Lab Podcast #3 (00:22:05) Adding Up Your Lights\n",
      "\n",
      "Content: wanna wake up earlier, so the simple way to think about this is if you're having trouble waking up early and feeling alert early in the day, you're going to wanna try and get bright light exposure even before waking up because it will advance your clock, it's sort of like turning the clock forward, whereas if you are having trouble waking up early, you definitely don't want to get too much light exposure or any light exposure to your eyes late in the evening and in the middle of the night because it's just gonna delay your clock more and more, so rather than get into the specifics of everybody's situation because there are many of you out there with different situations and lifestyle requirements, et cetera, the way to think about this is that you have these internal mechanisms of adenosine and circadian clocks, and they're always operating, and what you're trying to do is provide them anchors, you're trying to provide them consistent, powerful anchors so that your cortisol, your melatonin, and then everything that cascades down from that, like your metabolism and your ability to learn and your sense of alertness, your dopamine, your serotonin, all that stuff is timed regularly, one of the reasons why there's so much challenge out there with focus and anxiety and depression, there are a lot of reasons for that, but one of the reasons is that people's internal mechanisms aren't anchored to anything regular. Now, this doesn't require being neurotically attached to getting up at a very specific time, going outside, viewing the sunlight at the same time every day, these systems, again, will average, but if you can provide them consistent light anchors early in the day and in the evening, and avoiding light at night, you will be amazed at the tremendous number of positive effects that can come from that at the level of metabolic factors, hormones, and just general feelings of wellbeing, in fact, most of us are familiar with what it is to not sleep well and all the terrible effects that has, maybe one night you're fine, two nights even, for the new parents out there, I sympathize with you, but most people are not familiar with what it is to sleep really, really well on a consistent basis, and when you start doing that by controlling your sleep environment, right, get the proper sleep surface, get the proper pillow, get the temperature in the room right, get your light exposure right, start timing your exercise at normal periods or times\n",
      "Source: Master Your Sleep & Be More Alert When Awake | Huberman Lab Podcast #2 (00:55:40) How To Wake Up Earlier\n",
      "=========\n",
      "FINAL ANSWER:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "('Sunlight exposure in the morning is important because it triggers daytime '\n",
      " 'signals and alertness, and can help shift the circadian clock earlier. '\n",
      " 'Sunlight exposure around sunset can also help protect against the negative '\n",
      " 'effects of light later in the day. The brain and body need consistent and '\n",
      " 'powerful anchors of light to regulate hormones, metabolism, and overall '\n",
      " 'wellbeing. \\n')\n",
      "('Master Your Sleep & Be More Alert When Awake | Huberman Lab Podcast #2 '\n",
      " '(00:42:00) The Power of Sunset, Using Science to Optimize Sleep, Learning & '\n",
      " 'Metabolism | Huberman Lab Podcast #3 (00:22:05) Adding Up Your Lights, '\n",
      " 'Master Your Sleep & Be More Alert When Awake | Huberman Lab Podcast #2 '\n",
      " '(00:55:40) How To Wake Up Earlier')\n"
     ]
    }
   ],
   "source": [
    "foo = qa.answer(\"Why is it so important to have sunlight exposure in the morning?\")\n",
    "pprint.pprint(foo[\"answer\"])\n",
    "pprint.pprint(foo[\"sources\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "''\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(result[\"sources\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('There are some nootropics that can increase focus and acetylcholine '\n",
      " 'stimulation, such as caffeine, Coleen donors, and alpha GPC, but there is no '\n",
      " 'specific pill or chemical that will allow one to download more information '\n",
      " 'more quickly. Most nootropics tend to bundle a bunch of things together, '\n",
      " 'including stimulants and acetylcholine stimulators, but they tend to use '\n",
      " 'more of a shotgun approach than is probably going to be useful for learning '\n",
      " 'and memory in the long run. Modafinil or armodafinil can improve learning '\n",
      " 'and memory, but they are expensive and designed as stimulants for the '\n",
      " 'treatment of narcolepsy. The use of nootropics should be approached with '\n",
      " 'caution and occasional use, if safe for the individual. \\n')\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(result[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What are some nootropics that would help me learn a language faster?',\n",
       " 'answer': ' Nootropics that may help with learning a language faster include caffeine, alpha GPC, L-tyrosine, Adderall, and Modafinil. However, these should be approached with caution and only used occasionally.\\n',\n",
       " 'sources': 'Using Failures, Movement & Balance to Learn Faster | Huberman Lab Podcast #7 (1:19:25) Learning French and Other Things Faster\\nUsing Science to Optimize Sleep, Learning & Metabolism | Huberman Lab Podcast #3 (00:54:05) Smart Drugs'}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.answer(\"What are some nootropics that would \\\n",
    "help me learn a language faster?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 4097 tokens, however you requested 4391 tokens (4135 in your prompt; 256 for the completion). Please reduce your prompt; or completion length.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[132], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpprint\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m result \u001b[39m=\u001b[39m qa\u001b[39m.\u001b[39;49manswer(\u001b[39m\"\u001b[39;49m\u001b[39mHow would caffeine, alpha GPC, L-tyrosine, Adderall, and Modafinil\u001b[39;49m\u001b[39m\\\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m affect my ability to learn a language?\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      5\u001b[0m pprint\u001b[39m.\u001b[39mpprint(result[\u001b[39m\"\u001b[39m\u001b[39manswer\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      6\u001b[0m pprint\u001b[39m.\u001b[39mpprint(result[\u001b[39m\"\u001b[39m\u001b[39msources\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[122], line 19\u001b[0m, in \u001b[0;36mQA.answer\u001b[0;34m(self, question)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39manswer\u001b[39m(\u001b[39mself\u001b[39m, question):\n\u001b[0;32m---> 19\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchain({\n\u001b[1;32m     20\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mquestion\u001b[39;49m\u001b[39m\"\u001b[39;49m: question,\n\u001b[1;32m     21\u001b[0m     })\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chains/base.py:140\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    141\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chains/base.py:134\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    128\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    129\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m    130\u001b[0m     inputs,\n\u001b[1;32m    131\u001b[0m )\n\u001b[1;32m    132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 134\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    135\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    136\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    137\u001b[0m     )\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chains/qa_with_sources/base.py:128\u001b[0m, in \u001b[0;36mBaseQAWithSourcesChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    126\u001b[0m _run_manager \u001b[39m=\u001b[39m run_manager \u001b[39mor\u001b[39;00m CallbackManagerForChainRun\u001b[39m.\u001b[39mget_noop_manager()\n\u001b[1;32m    127\u001b[0m docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_docs(inputs)\n\u001b[0;32m--> 128\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcombine_documents_chain\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m    129\u001b[0m     input_documents\u001b[39m=\u001b[39;49mdocs, callbacks\u001b[39m=\u001b[39;49m_run_manager\u001b[39m.\u001b[39;49mget_child(), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs\n\u001b[1;32m    130\u001b[0m )\n\u001b[1;32m    131\u001b[0m \u001b[39mif\u001b[39;00m re\u001b[39m.\u001b[39msearch(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSOURCES:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m, answer):\n\u001b[1;32m    132\u001b[0m     answer, sources \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msplit(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSOURCES:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m, answer)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chains/base.py:239\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(args[\u001b[39m0\u001b[39m], callbacks\u001b[39m=\u001b[39mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[1;32m    238\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m--> 239\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[1;32m    241\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`run` supported with either positional arguments or keyword arguments\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m but not both. Got args: \u001b[39m\u001b[39m{\u001b[39;00margs\u001b[39m}\u001b[39;00m\u001b[39m and kwargs: \u001b[39m\u001b[39m{\u001b[39;00mkwargs\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    244\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chains/base.py:140\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    141\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chains/base.py:134\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    128\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    129\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m    130\u001b[0m     inputs,\n\u001b[1;32m    131\u001b[0m )\n\u001b[1;32m    132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 134\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    135\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    136\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    137\u001b[0m     )\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chains/combine_documents/base.py:84\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[1;32m     83\u001b[0m other_keys \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key}\n\u001b[0;32m---> 84\u001b[0m output, extra_return_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcombine_docs(\n\u001b[1;32m     85\u001b[0m     docs, callbacks\u001b[39m=\u001b[39;49m_run_manager\u001b[39m.\u001b[39;49mget_child(), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mother_keys\n\u001b[1;32m     86\u001b[0m )\n\u001b[1;32m     87\u001b[0m extra_return_dict[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key] \u001b[39m=\u001b[39m output\n\u001b[1;32m     88\u001b[0m \u001b[39mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chains/combine_documents/stuff.py:87\u001b[0m, in \u001b[0;36mStuffDocumentsChain.combine_docs\u001b[0;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_inputs(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     86\u001b[0m \u001b[39m# Call predict on the LLM.\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm_chain\u001b[39m.\u001b[39;49mpredict(callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs), {}\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chains/llm.py:213\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, callbacks: Callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    199\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \n\u001b[1;32m    201\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[39m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chains/base.py:140\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    141\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chains/base.py:134\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    128\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    129\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m    130\u001b[0m     inputs,\n\u001b[1;32m    131\u001b[0m )\n\u001b[1;32m    132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 134\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    135\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    136\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    137\u001b[0m     )\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chains/llm.py:69\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\n\u001b[1;32m     65\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     66\u001b[0m     inputs: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m     67\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     68\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m---> 69\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate([inputs], run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m     70\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_outputs(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chains/llm.py:79\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m     78\u001b[0m prompts, stop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_prompts(input_list, run_manager\u001b[39m=\u001b[39mrun_manager)\n\u001b[0;32m---> 79\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[1;32m     80\u001b[0m     prompts, stop, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m     81\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/llms/base.py:127\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[1;32m    121\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    122\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m    123\u001b[0m     stop: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    124\u001b[0m     callbacks: Callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    125\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    126\u001b[0m     prompt_strings \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_string() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_strings, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/llms/base.py:176\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    175\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 176\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    177\u001b[0m run_manager\u001b[39m.\u001b[39mon_llm_end(output)\n\u001b[1;32m    178\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/llms/base.py:170\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks)\u001b[0m\n\u001b[1;32m    165\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[1;32m    166\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m}, prompts\n\u001b[1;32m    167\u001b[0m )\n\u001b[1;32m    168\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m     output \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 170\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(prompts, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    171\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    172\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop)\n\u001b[1;32m    173\u001b[0m     )\n\u001b[1;32m    174\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    175\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/llms/openai.py:306\u001b[0m, in \u001b[0;36mBaseOpenAI._generate\u001b[0;34m(self, prompts, stop, run_manager)\u001b[0m\n\u001b[1;32m    304\u001b[0m     choices\u001b[39m.\u001b[39mextend(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    305\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 306\u001b[0m     response \u001b[39m=\u001b[39m completion_with_retry(\u001b[39mself\u001b[39;49m, prompt\u001b[39m=\u001b[39;49m_prompts, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    307\u001b[0m     choices\u001b[39m.\u001b[39mextend(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    308\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstreaming:\n\u001b[1;32m    309\u001b[0m     \u001b[39m# Can't update token usage if streaming\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/llms/openai.py:106\u001b[0m, in \u001b[0;36mcompletion_with_retry\u001b[0;34m(llm, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    104\u001b[0m     \u001b[39mreturn\u001b[39;00m llm\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 106\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/llms/openai.py:104\u001b[0m, in \u001b[0;36mcompletion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 104\u001b[0m     \u001b[39mreturn\u001b[39;00m llm\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/openai/api_requestor.py:230\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    210\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    211\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    218\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    219\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    220\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    221\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    222\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    229\u001b[0m     )\n\u001b[0;32m--> 230\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    231\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/openai/api_requestor.py:624\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    617\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    618\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    619\u001b[0m         )\n\u001b[1;32m    620\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    621\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 624\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    625\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    626\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    627\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    628\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    629\u001b[0m         ),\n\u001b[1;32m    630\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    631\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/openai/api_requestor.py:687\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    685\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    686\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 687\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    688\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    689\u001b[0m     )\n\u001b[1;32m    690\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens, however you requested 4391 tokens (4135 in your prompt; 256 for the completion). Please reduce your prompt; or completion length."
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "result = qa.answer(\"How would caffeine, alpha GPC, L-tyrosine, Adderall, and Modafinil\\\n",
    " affect my ability to learn a language?\")\n",
    "\n",
    "pprint.pprint(result[\"answer\"])\n",
    "pprint.pprint(result[\"sources\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "978\n",
      "621\n",
      "514\n",
      "525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2638"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for d in docsearch.search(\"What is Alpha GPC?\"):\n",
    "    print(count_tokens(d.page_content))\n",
    "\n",
    "sum([count_tokens(d.page_content) for d in docsearch.search(\"What is Alpha GPC?\")])\n",
    "# sum([count_tokens(str(d.metadata)) for d in docsearch.search(\"What is Alpha GPC?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'How to Learn Skills Faster | Huberman Lab Podcast #20 (01:39:00) '\n",
      "           'Ingestible Compounds That Support Skill Learning: Motivation, '\n",
      "           'Repetitions, Alpha-GPC',\n",
      " 'summary': '(01:39:00) Ingestible Compounds That Support Skill Learning: '\n",
      "            'Motivation, Repetitions, Alpha-GPC',\n",
      " 'title': 'How to Learn Skills Faster | Huberman Lab Podcast #20'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(docsearch.search(\"What is Alpha GPC?\")[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 4097 tokens, however you requested 4541 tokens (4285 in your prompt; 256 for the completion). Please reduce your prompt; or completion length.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[117], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[39m=\u001b[39m qa\u001b[39m.\u001b[39;49manswer(\u001b[39m\"\u001b[39;49m\u001b[39mWhat is Alpha GPC?\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(result[\u001b[39m\"\u001b[39m\u001b[39manswer\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(result[\u001b[39m\"\u001b[39m\u001b[39msources\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[116], line 19\u001b[0m, in \u001b[0;36mQA.answer\u001b[0;34m(self, question)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39manswer\u001b[39m(\u001b[39mself\u001b[39m, question):\n\u001b[0;32m---> 19\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchain({\n\u001b[1;32m     20\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mquestion\u001b[39;49m\u001b[39m\"\u001b[39;49m: question,\n\u001b[1;32m     21\u001b[0m     })\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chains/base.py:140\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    141\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chains/base.py:134\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    128\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    129\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m    130\u001b[0m     inputs,\n\u001b[1;32m    131\u001b[0m )\n\u001b[1;32m    132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 134\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    135\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    136\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    137\u001b[0m     )\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chains/qa_with_sources/base.py:128\u001b[0m, in \u001b[0;36mBaseQAWithSourcesChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    126\u001b[0m _run_manager \u001b[39m=\u001b[39m run_manager \u001b[39mor\u001b[39;00m CallbackManagerForChainRun\u001b[39m.\u001b[39mget_noop_manager()\n\u001b[1;32m    127\u001b[0m docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_docs(inputs)\n\u001b[0;32m--> 128\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcombine_documents_chain\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m    129\u001b[0m     input_documents\u001b[39m=\u001b[39;49mdocs, callbacks\u001b[39m=\u001b[39;49m_run_manager\u001b[39m.\u001b[39;49mget_child(), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs\n\u001b[1;32m    130\u001b[0m )\n\u001b[1;32m    131\u001b[0m \u001b[39mif\u001b[39;00m re\u001b[39m.\u001b[39msearch(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSOURCES:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m, answer):\n\u001b[1;32m    132\u001b[0m     answer, sources \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msplit(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSOURCES:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m, answer)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chains/base.py:239\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(args[\u001b[39m0\u001b[39m], callbacks\u001b[39m=\u001b[39mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[1;32m    238\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m--> 239\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[1;32m    241\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`run` supported with either positional arguments or keyword arguments\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m but not both. Got args: \u001b[39m\u001b[39m{\u001b[39;00margs\u001b[39m}\u001b[39;00m\u001b[39m and kwargs: \u001b[39m\u001b[39m{\u001b[39;00mkwargs\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    244\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chains/base.py:140\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    141\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chains/base.py:134\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    128\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    129\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m    130\u001b[0m     inputs,\n\u001b[1;32m    131\u001b[0m )\n\u001b[1;32m    132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 134\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    135\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    136\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    137\u001b[0m     )\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chains/combine_documents/base.py:84\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[1;32m     83\u001b[0m other_keys \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key}\n\u001b[0;32m---> 84\u001b[0m output, extra_return_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcombine_docs(\n\u001b[1;32m     85\u001b[0m     docs, callbacks\u001b[39m=\u001b[39;49m_run_manager\u001b[39m.\u001b[39;49mget_child(), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mother_keys\n\u001b[1;32m     86\u001b[0m )\n\u001b[1;32m     87\u001b[0m extra_return_dict[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key] \u001b[39m=\u001b[39m output\n\u001b[1;32m     88\u001b[0m \u001b[39mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chains/combine_documents/stuff.py:87\u001b[0m, in \u001b[0;36mStuffDocumentsChain.combine_docs\u001b[0;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_inputs(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     86\u001b[0m \u001b[39m# Call predict on the LLM.\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm_chain\u001b[39m.\u001b[39;49mpredict(callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs), {}\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chains/llm.py:213\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, callbacks: Callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    199\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \n\u001b[1;32m    201\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[39m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chains/base.py:140\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    141\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chains/base.py:134\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    128\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    129\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m    130\u001b[0m     inputs,\n\u001b[1;32m    131\u001b[0m )\n\u001b[1;32m    132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 134\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    135\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    136\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    137\u001b[0m     )\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chains/llm.py:69\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\n\u001b[1;32m     65\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     66\u001b[0m     inputs: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m     67\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     68\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m---> 69\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate([inputs], run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m     70\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_outputs(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chains/llm.py:79\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m     78\u001b[0m prompts, stop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_prompts(input_list, run_manager\u001b[39m=\u001b[39mrun_manager)\n\u001b[0;32m---> 79\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[1;32m     80\u001b[0m     prompts, stop, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m     81\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/llms/base.py:127\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[1;32m    121\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    122\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m    123\u001b[0m     stop: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    124\u001b[0m     callbacks: Callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    125\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    126\u001b[0m     prompt_strings \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_string() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_strings, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/llms/base.py:176\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    175\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 176\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    177\u001b[0m run_manager\u001b[39m.\u001b[39mon_llm_end(output)\n\u001b[1;32m    178\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/llms/base.py:170\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks)\u001b[0m\n\u001b[1;32m    165\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[1;32m    166\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m}, prompts\n\u001b[1;32m    167\u001b[0m )\n\u001b[1;32m    168\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m     output \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 170\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(prompts, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    171\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    172\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop)\n\u001b[1;32m    173\u001b[0m     )\n\u001b[1;32m    174\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    175\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/llms/openai.py:306\u001b[0m, in \u001b[0;36mBaseOpenAI._generate\u001b[0;34m(self, prompts, stop, run_manager)\u001b[0m\n\u001b[1;32m    304\u001b[0m     choices\u001b[39m.\u001b[39mextend(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    305\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 306\u001b[0m     response \u001b[39m=\u001b[39m completion_with_retry(\u001b[39mself\u001b[39;49m, prompt\u001b[39m=\u001b[39;49m_prompts, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    307\u001b[0m     choices\u001b[39m.\u001b[39mextend(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    308\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstreaming:\n\u001b[1;32m    309\u001b[0m     \u001b[39m# Can't update token usage if streaming\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/llms/openai.py:106\u001b[0m, in \u001b[0;36mcompletion_with_retry\u001b[0;34m(llm, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    104\u001b[0m     \u001b[39mreturn\u001b[39;00m llm\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 106\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/llms/openai.py:104\u001b[0m, in \u001b[0;36mcompletion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 104\u001b[0m     \u001b[39mreturn\u001b[39;00m llm\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/openai/api_requestor.py:230\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    210\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    211\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    218\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    219\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    220\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    221\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    222\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    229\u001b[0m     )\n\u001b[0;32m--> 230\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    231\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/openai/api_requestor.py:624\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    617\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    618\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    619\u001b[0m         )\n\u001b[1;32m    620\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    621\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 624\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    625\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    626\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    627\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    628\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    629\u001b[0m         ),\n\u001b[1;32m    630\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    631\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/openai/api_requestor.py:687\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    685\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    686\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 687\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    688\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    689\u001b[0m     )\n\u001b[1;32m    690\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens, however you requested 4541 tokens (4285 in your prompt; 256 for the completion). Please reduce your prompt; or completion length."
     ]
    }
   ],
   "source": [
    "result = qa.answer(\"What is Alpha GPC?\")\n",
    "print(result[\"answer\"])\n",
    "print(result[\"sources\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='\\n-\\n  \\nIf you really need to learn conversational French to save your relationship, the chances are you\\'re going to learn it. There are limits, of course, to the extent to which one can accentuate or accelerate plasticity. The ceiling on this is not infinite, although we don\\'t know how high it goes. I think it\\'s reasonable to say that if someone put a gun to my head and said, \"Learn conversational French in the next 120 seconds,\" that conversational French will be limited probably to just one word, probably the word oui or something like that. Because I can\\'t stuff in all the knowledge all at once. I think that\\'s the dream of brain-machine interface, that one will be able to download a chip into their hippocampus or cortex, or some other brain structure that would allow them to download conversational French. And someday we may get to that, that capability may come about. Right now, it does not exist, nor is there a specific pill or chemical that will allow you to download more information more quickly. This is the issue around nootropics I\\'ve talked about before. There are things that can increase focus, mainly things that increase acetylcholine and transmission through the nicotine system, things that can increase dopamine, things like L-tyrosine. Again, I\\'m not recommending these. You need to heed the warnings on those bottles, but they will increase these neurochemicals. And there are, of course, things that will increase epinephrin, things like caffeine, or some people, because of prescription, take Adderall. I\\'m, again, not suggesting people take any of these things. In fact, today I focused almost exclusively on behavioral tools and ways of structuring learning bouts that will allow you to access more plasticity regardless of age. And they center around things that I\\'m sure if you look around you you\\'ll see evidence for, \"Oh, incremental learning is powerful,\" or, \"Oh, the vestibular system can open up opportunities for plasticity.\" I\\'m sure that the yogis out there all saying, \"Wait, this sounds exactly like yoga. We\\'re supposed to push to an edge and do these inversions and do all those sorts of things.\" Well, I want to be clear, I never said anyone should do inversions. I said that the vestibular system is a valuable portal into some of these neurochemical states that favor plasticity.\\n', metadata={'title': 'Using Failures, Movement & Balance to Learn Faster | Huberman Lab Podcast #7', 'summary': '(1:19:25) Learning French and Other Things Faster'}),\n",
       " Document(page_content=\"\\n-\\n  \\nWhich brings us to the next thing about learning and plasticity which is nootropics, AKA smart drugs. [sighs] This is a big topic that sigh was a sigh of concern about how to address nootropics in a thorough enough, but thoughtful enough way. Look, I have a lot of thoughts about nootropics. First of all, it means smart drugs, I believe. And I don't like that phrase because let's just take a step back and think about exercise. You just say, I want to be more physically fit. What does that mean? Does it mean I would ask for more specificity, I'd say, Do you want to be stronger? Okay, maybe you need to lift heavier objects progressively. Do you want more endurance very different protocol to access endurance. Do you want flexibility? Do you want explosiveness or suppleness? Huge range of things that we call physical fitness. Maybe you want all of those. If we were talking about emotional fitness we would say, well, inability to feel empathy but probably also to disengage from empathy because you don't want to be tethered to other people's emotions all the time. That's not healthy either. You would think about being able to access a range of emotions, but for some people their range into the sadness regime is really quite vast but their range into the happiness regime might be kind of limited. For other people who are in a manic state, it might be, they can access all that happy stuff but not the sadder stuff. So I'm speaking by way of analogy here. But if we say we're talking about cognitive and cognitive abilities we have to ask, okay, creativity, memory. We tend to associate intelligence with memory. And I think this goes back to like spelling bees or something, the ability to retain a lot of information and just regurgitate information which will get you some distance in some disciplines of life. But it won't allow you creative thinking, it's necessary for creative thinking. You need a knowledge base, right? You can't just look up everything on Google, despite what you know, certain educators or so-called educators say, you need a database so that you can have the raw materials with which to be creative. So necessary to have memory but not sufficient to be creative, right? The creative could have a poor memory for certain things but certainly not for everything. They can't have anterograde and retrograde amnesia. They'd be like the goldfish that every time around the tank, it, you know I can't remember where it's at. I actually don't know that they've ever done that experiment by the way, but you know, so no disrespect to goldfish but you know, so you get the idea. You've got creativity, you have memory, you have the ability to task switch, right? You have the ability to strategy development, strategy implement. So the problem I have with the concept of a nootropic or a smart drug is it's not specific as to what cognitive algorithm you're trying to engage. We need more specificity. That said, there are elements to learning that we've discussed here before that are very concrete things like the ability to focus and put the blinders on to everything else that's happening in around you and in your head mainly, right? Distractions about things you should be doing, could be doing or might be doing and focus on what you need to do. And then that's required for triggering the acetylcholine neuromodulator that will then allow you to highlight the particular synopsis that will then later change in sleep. So no nootropic allows you to bypass the need for sleep in deep rest. That's important to understand. So I daydream about a day when people will be able to access compounds that are safe, that will allow them to learn better meaning, to access information, focus better, as well as to sleep better and activate the plasticity from the learning about. Right now most nootropics tend to bundle a bunch of things together. Most of them include some form of stimulant, caffeine. Episode two, I'll tell you more probably than you ever wanted to know about caffeine, adenosine and how that works. So refer there for how caffeine works. But stimulants will allow you to increase focus up to a particular point. If you have too little alertness in your system, you can't focus, too much however, you start to cliff and focus drifts, okay? So you can't just ingest more stimulant to be more focused. It doesn't work that way. Most nootropics also include things that increase or a desire to increase acetylcholine. Things like alpha GPC and other things of that sort. And indeed, there's some evidence that they can increase acetylcholine. I refer you again to examine.com the website to evaluate any supplements or compounds for their safety and their effects in humans and animals, free website as well as with links to studies. So we need the focus component. We need the alertness component. The alertness component comes from epinephrin, traditionally from caffeine stimulation. The acetylcholine stimulation traditionally comes from Coleen donors or alpha GPC, things of that sort. And then you would want to have some sort of off switch, because anything that's going to really stimulate your alertness, that then provides a crash. That crash is not a crash into the deep kind of restful slumber that you would want for learning, it's a crash into the kind of, let's just call it lopsided sleep, meaning it's deep sleep but it lacks certain spindles and other elements of the physiology sleep spindles, that really engage the learning process and the reconfiguration of synopsis. So right now, my stance on nootropics is that maybe, maybe for occasional use, provided it's safe for you, I'm not recommending it, but in general it tends to use more of a shotgun approach than is probably going to be useful for learning and memory in the long run. A lot of people ask about Modafinil or armodafinil which was designed for treatment of narcolepsy. So right there, it tells you it's a stimulant. And yes, there is evidence, it will improve learning memory. Modafinil is very expensive. Last time I checked our Modafinil I think is the recent released a generic version of this that's far less expensive. Most of these things look a lot like amphetamine and many of them have the potential for addiction or can be habit forming. But more importantly, a lot of those things also can create metabolic effects by disruption to insulin receptors and so forth. So you want to approach those with a strong sense of caution. Now, there are the milder things that act as nootropics that I mentioned, some of them like alpha GPC. Some people like Gingko. Gingko gives me vicious headaches, so I don't take it. So people really differ.\\n\", metadata={'title': 'Using Science to Optimize Sleep, Learning & Metabolism | Huberman Lab Podcast #3', 'summary': '(00:54:05) Smart Drugs'}),\n",
       " Document(page_content=\"\\nAnd last but not least in terms of these different compounds, I do want to mention the Racetams. These are somewhat esoteric and probably most of you haven't heard about them, but some of you probably know a lot about them and they are becoming more popular. They go by names like New pepped and things of that sort. The Racetams. are illegal in certain countries. They are gray market in other countries, and they are sold over the counter in this country, in the U.S. so they have different margins for safety you definitely need to consult your doctor, especially if you have ADHD, but new pepped has been shown when taken, at 10 milligrams, twice daily can be more effective than some of the other Racetams. What is Noopept? Noopept taps into the cholinergic system, the acetylcholine system in ways, very similar to alpha-GPC, but seems to have a slightly higher affinity for some of the receptors involved and can lead to those heightened states of cognitive capacity and there are these studies one in particular, comparative studies of new pepped, Racetams in the treatment of patients with mild cognitive disorders and brain diseases of vascular and traumatic origin. That's a mouthful. What this study basically points to is the fact that people who are experiencing some degree of inability to focus due to prior concussion or some vascular event, a stroke or a schemey of any kind, because neurons need blood, when the blood supply is cut off to neurons, or when there's a bleed in the brain. Subsequent to that, often there are challenges in maintaining focus. This is very common for people who have done sports, where there's a lot of running into each other with your head like rugby football, hockey, and so forth, but also people who have experienced head blows or often overlooked is the fact that most traumatic head injury is not actually from sports, even football it's from things like construction work from high-impact work of that kind. So there does seem to be some efficacy of new Pepped and Racetams. and things like it. It's an emerging area and as I mentioned in the U.S. these things are sold over the counter. Again, you have to figure out if it's right for you, but they are beginning to show some promise, and I'm intrigued by them because of the way that they tap into the cholinergic system, which is both directly involved in focus, and the ability to focus, but is also important for things related to age-related cognitive decline. So a decline in cholinergic transmission or acetylcholine as we call it in the brain is one of the things associated with cognitive decline and it does seem that increasing cholinergic transmission can offset some of that cognitive decline and perhaps even more so in conditions such as vascular damage or concussion to the brain. If you're interested in atypical treatments for ADHD compounds or improve focus and related themes, and you like reading about this stuff, there's an excellent review article that I can refer you to it's by Ahn et al, AHN it was published in 2016 so it's a little bit behind the times, although it's surprisingly comprehensive given that, which lines up all the various drugs that I've discussed, Racetams., and Adderall and Ritalin, and various forms of dopaminergic agents and cholinergic agents spells out whether or not they are sold over the counter by prescription, and really lines them up in all their effects, their drawbacks, et cetera. I'll refer you to that study. It's available in its full length form online for free it's Hen et al the journal is neuro plasticity, neural plasticity, 2016 should be very easy to find if you put those keywords in, and while it is a review, it is a very comprehensive review and if you're really into this stuff, and you also want to learn a thing or two about how these things interact with neurofeedback, et cetera, there's some information in there as well. \\n\", metadata={'title': 'ADHD & How Anyone Can Improve Their Focus | Huberman Lab Podcast #37', 'summary': '(2:01:23) \\tRacetams, Noopept '}),\n",
       " Document(page_content='\\n-\\n  \\nThat can feel stressful, but that\\'s one of the reasons you procrastinators out there, people are always asking me what can be done for procrastination? What can be done for procrastination is you can understand what\\'s happening, which is that you are self-imposing stress because stress acts like a drug. It is a powerful nootropic. I get asked about nootropics. The most powerful nootropic or smart drug is stress. It\\'s the concern of failure. It\\'s the desire to do well. It\\'s the impending deadline. It\\'s the, \"Oh my gosh, I have to do this thing now or I\\'m going to fail.\" That is the best nootropic you will ever find. That combined with a good night\\'s sleep, which we\\'ll talk about. But we spent a whole month on sleep. So, I don\\'t want to backtrack too much. Okay. So, short-term stress, great. The key is to be able to turn the stress response off when you\\'re done, when you don\\'t want that. In fact, let\\'s just really tamp down the relationship between the short-term or acute stress response and infection.\\n', metadata={'title': 'Tools for Managing Stress & Anxiety | Huberman Lab Podcast #10', 'summary': '(00:52:02) Procrastination and Self-Manufactured Nootropics'})]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = docsearch.search(\"What are some nootropics that would help me learn a language faster?\")\n",
    "\n",
    "docs[0].metadata[\"summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 5267, which is longer than the specified 1000\n",
      "Created a chunk of size 3991, which is longer than the specified 1000\n",
      "Created a chunk of size 2007, which is longer than the specified 1000\n",
      "Created a chunk of size 2573, which is longer than the specified 1000\n",
      "Created a chunk of size 1121, which is longer than the specified 1000\n",
      "Created a chunk of size 3077, which is longer than the specified 1000\n",
      "Created a chunk of size 1054, which is longer than the specified 1000\n",
      "Created a chunk of size 1638, which is longer than the specified 1000\n",
      "Created a chunk of size 1105, which is longer than the specified 1000\n",
      "Created a chunk of size 2601, which is longer than the specified 1000\n",
      "Created a chunk of size 3258, which is longer than the specified 1000\n",
      "Created a chunk of size 1047, which is longer than the specified 1000\n",
      "Created a chunk of size 4688, which is longer than the specified 1000\n",
      "Created a chunk of size 3415, which is longer than the specified 1000\n",
      "Created a chunk of size 4930, which is longer than the specified 1000\n",
      "Created a chunk of size 4864, which is longer than the specified 1000\n",
      "Created a chunk of size 3846, which is longer than the specified 1000\n",
      "Created a chunk of size 5045, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "# </details>\n",
    "\n",
    "# <details>\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "markdown_path = \"md_transcripts/01. How Your \\\n",
    "Nervous System Works & Changes.md\"\n",
    "with open(markdown_path) as f:\n",
    "    markdown_text = f.read()\n",
    "\n",
    "separator_str = \"</details>\\n\\n<details>\"\n",
    "\n",
    "splitter = CharacterTextSplitter(chunk_size=1000,\n",
    "                                         chunk_overlap=100,\n",
    "                                         separator=separator_str)\n",
    "# docs = splitter.create_documents([markdown_text])\n",
    "texts = splitter.split_text(markdown_text)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.text_splitter import MarkdownTextSplitter\n",
    "\n",
    "# markdown_path = \"md_transcripts/01. How Your \\\n",
    "# Nervous System Works & Changes.md\"\n",
    "# with open(markdown_path) as f:\n",
    "#     markdown_text = f.read()\n",
    "\n",
    "# markdown_splitter = MarkdownTextSplitter(chunk_size=10**4,\n",
    "#                                          chunk_overlap=100)\n",
    "# docs = markdown_splitter.create_documents([markdown_text])\n",
    "\n",
    "# embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**How Your Nervous System Works & Changes | Huberman Lab Podcast #1**\n",
      "\n",
      "[**https://www.youtube.com/watch?v=H-XfCl-HpRM&t=2s**](https://www.youtube.com/watch?v=H-XfCl-HpRM&t=2s)\n",
      "\n",
      "**TRANSCRIPT**\n",
      "\n",
      "<details>\n",
      "<summary>(00:00) Introduction</summary>\n",
      "-\n",
      "    \n",
      "Welcome to the Huberman Lab Podcast where we discuss science and science-based tools for everyday life. (upbeat guitar music) I'm Andrew Huberman and I'm a professor of neurobiology and ophthalmology at Stanford School of Medicine. For today's podcast we're going to talk about the parts list of the nervous system. Now that might sound boring, but these are the bits and pieces that together make up everything about your experience of life, from what you think about to what you feel, what you imagine, and what you accomplish from the day you're born until the day you die. That parts list is really incredible because it has a history associated with it that really provides a window into all sorts of things like engineering, warfare, religion, and philosophy. So I'm going to share with you the parts list that makes up who you are through the lens of some of those other aspects of life and other aspects of the history of the discovery of the nervous system. By the end of this podcast I promise you're going to understand a lot more about how you work and how to apply that knowledge. There's going to be a little bit of story. There's going to be a lot of discussion about the people who made these particular discoveries. There'll be a little bit of technical language. There's no way to avoid that. But at the end you're going to have in hand what will be the equivalent of an entire semester of learning about the nervous system and how you work So a few important points before we get started. I am not a medical doctor. That means I don't prescribe anything. I'm a professor, so sometimes I'll profess things. In fact, I profess a lot of things. We are going to talk about some basic functioning of the nervous system parts and et cetera, but we're also going to talk about how to apply that knowledge. That said, your healthcare, your wellbeing is your responsibility. So anytime we talk about tools please filter it through that responsibility. Talk to a healthcare professional if you're going to explore any new tools or practices and be smart in your pursuit of these new tools. Also wanna emphasize that this podcast and the other things I do on social media are my personal goal of bringing zero cost to consumer information to the general public. It is separate from my role at Stanford University. \n",
      "  \n",
      "In that spirit I really want to thank the sponsors of today's podcast. The first one is Athletic Greens which is an all-in-one drink. It's a greens drink that has vitamins, minerals, probiotics, prebiotics. I've been using Athletic Greens since 2012 so I'm really delighted that they're sponsoring the podcast. The reason I like it is because I like vitamins and minerals, I think they're important to my health and it can be kind of overwhelming to know what to take in that landscape. So by taking one thing that also happens to taste really good I get all the vitamins minerals, et cetera, that I need. There's also a lot of data there now about the importance of the gut microbiome for immune health and for the gut brain access, all these things. And the probiotics and prebiotics are important to me for that reason. If you want to try Athletic Greens you can go to athleticgreens.com/huberman, and put in the code word Huberman at checkout. If you do that they'll send you a year's supply of vitamin D3 and K2. There's a lot in the news lately about the importance of vitamin D3. We can all get vitamin D3 from sunlight but many of us aren't getting enough sunlight. Vitamin D3 has been shown to be relevant to the immune system and the hormone systems, et cetera. So once again that's athleticgreens.com/huberman, enter Huberman at checkout, and you get the year supply of D3 and K2 along with your Athletic Greens. \n",
      "  \n",
      "This podcast is also brought to us by Inside Tracker which is a health monitoring company. It uses blood tests and saliva tests to look at things like DNA and metabolic markers and monitors your hormones, a huge number of different parameters of health that really can only be measured accurately through blood and saliva tests. I use Inside Tracker because I'm a big believer in data. There's a lot of aspects to our biology that can only be accurately measured by way of blood tests and saliva tests. The thing that's really nice about Inside Tracker is that rather than just giving you a bunch of numbers back of the levels of these things in your body, it gives you, through a really simple platform, information about what to do with all those levels of hormones and metabolic markers, et cetera. It also has a feature which is particularly interesting which it measures your inner age, which is more a measure of your biological age as opposed to your chronological age. And all that information is organized so that you can make changes in your nutritional regimes or your exercise regimes and watch how those markers change over time. So if you want to try Inside Tracker you can go to insidetracker.com/huberman and they'll give you 25% off at checkout.<summary>(05:00) What is the Nervous System</summary>\n",
      "-\n",
      "    \n",
      "So let's talk about the nervous system. The reason I say your nervous system and not your brain is because your brain is actually just one piece of this larger, more important thing, frankly, that we call the nervous system. The nervous system includes your brain and your spinal cord but also all the connections between your brain and your spinal cord and the organs of your body. It also includes, very importantly, all the connections between your organs back to your spinal cord and brain. So the way to think about how you function at every level from the moment you're born until the day you die, everything you think and remember and feel and imagine is that your nervous system is this continuous loop of communication between the brain, spinal cord, and body and body, spinal cord, and brain. In fact, we really can't even separate them. It's one continuous loop. You may have heard of something called a Mobius strip. A Mobius strip is almost like one of these impossible figures that no matter which angle you look at it from you can't tell where it starts and where it ends. And that's really how your nervous system is built. That's the structure that allows you to, for instance, deploy immune cells, to release cells that will go kill infection when you're in the presence of infection. Most people just think about that as a function of the immune system but actually it's your nervous system that tells organs like your spleen to release killer cells that go and hunt down those bacterial and viral invaders and gobble them up. If you have a stomach ache, for instance, sure, you feel that in your stomach, but it's really your nervous system that's causing the stomach ache. The ache aspect of it is a nervous system feature. So when we want to talk about experience or we want to talk about how to change the self in any way, we really need to think about the nervous system first. It is fair to say that the nervous system governs all other biological systems of the body, and it's also influenced by those other biological systems. So if we're talking about the nervous system we need to get a little specific about what we mean. It's not just this big loop of wires. In fact, there's a interesting story about that because at the turn of the sort of 1800s to 1900s, it actually was believed that our nervous system was just one giant cell. But two guys, that names aren't super important, but in fairness to their important discovery, Ramon y Cajal, a Spaniard, Camillo Golgi, an Italian guy, figured out how to label or stain the nervous system in a way that revealed, oh my goodness, we're actually made up of trillions of these little cells, nerve cells that are called neurons. And that's what a neuron is. It's just a nerve cell. They also saw that those nerve cells weren't touching one another. They're actually separated by little gaps. And those little gaps you may have heard of before, they're called synapses. Those synapses are where the chemicals from one neuron are kind of spit out or vomited into. And then the next nerve cell detects those chemicals and then passes electricity down its length to the next nerve cell and so forth. So really the way to think about your body and your thoughts and your mind is that you are a flow of electricity, right? There's nothing mystical about this. You're a flow of electricity between these different nerve cells. And depending on which nerve cells are active you might be lifting your arm or lowering your arm. You might be seeing something and perceiving that it's red or you might be seeing something and perceiving that it's green, all depending on which nerve cells are electrically active at a given moment. The example of perceiving red or perceiving green is a particularly good example because so often our experience of the world makes it seem as if these out these things that are happening outside us are actually happening inside us.\n"
     ]
    }
   ],
   "source": [
    "print(texts[0] + texts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "docsearch = Chroma.from_texts(texts, embeddings, \n",
    "    metadatas=[{\"source\": str(i)} for i in range(len(texts))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"<summary>(08:55) Deja Vu</summary>\\n-\\n    \\nBut the language of the nervous system is just electricity. It's just like a Morse code of some sort or the syllables and words and consonants and vowels of language. It just depends on how they're assembled, what order. And so that brings us to the issue of how the nervous system works. The way to think about how the nervous system works is that our experiences, our memories, everything is sort of like the keys on a piano being played in a particular order, right? If I play the keys on a piano in a particular order and with a particular intensity, that's a given song. We can make that analogous to a given experience. It's not really that the key, you know, A sharp or E flat is the song. It's just one component of the song. So when you hear that, you know, for instance, there's a brain area called the hippocampus, which there is, that's involved in memory. Well, it's involved in memory, but it's not that memories are stored there as, you know, sentences. They're stored there as patterns of electricity in neurons that when repeated, give you the sense that you are experiencing the thing again. In fact, deja vu, the sense that what you're experiencing is so familiar and like something that you've experienced previously is merely that the neurons that were active in one circumstance are now becoming active in the same circumstance again. And so it's really just like hearing the same song maybe not played on a piano but next time on a classical guitar, there's something similar about that song even though it's being played on two different instruments. So I think it's important that people understand the parts of their nervous system, and that it includes so much more than just the brain and that there are these things, neurons and synapses. But really that it's the electrical activity of these neurons that dictates our experience. So if the early 1900s were when these neurons were discovered, certainly a lot has happened since then.\", metadata={'source': '2'}),\n",
       " Document(page_content=\"<summary>(27:40) Thoughts & Thought Control</summary>\\n-\\n  \\nThoughts are really interesting because in many ways they're like perceptions except that they draw on not just what's happening in the present but also things we remember from the past and things that we anticipate about the future. The other thing about thoughts that's really interesting is that thoughts can be both reflexive, they can just be occurring all the time sort of like pop-up windows on a poorly filtered web browser, or they can be deliberate. We can decide to have a thought. In fact, right now you could decide to have a thought just like you would decide to write something out on a piece of paper. You could decide that you're listening to a podcast, that you are in a particular location. You're not just paying attention to what's happening, you're directing your thought process. And a lot of people don't understand or at least appreciate that the thought patterns and the neural circuits that underlie thoughts can actually be controlled in this deliberate way.\", metadata={'source': '12'}),\n",
       " Document(page_content=\"<summary>(21:15) Focusing the Mind</summary>\\n-\\n  \\nIf reflexive action tends to be what we call bottom up, deliberate action and deliberate perceptions and deliberate thoughts are top down. They require some effort and some focus. But that's the point, you can decide to focus your attention and energy on anything you want. You can decide to focus your behavior in any way you want. But it will always feel like it requires some effort and some strain. Whereas when you're in reflexive mode, just walking and talking and eating and doing your thing it's going to feel very easy. And that's because your nervous system basically wired up to be able to do most things easily without much metabolic demand, without consuming much energy. But the moment you try and do something very specific, you're going to feel a sort of mental friction. It's going to be challenging.\", metadata={'source': '9'}),\n",
       " Document(page_content=\"<summary>(17:30) Perceptions & The Spotlight of Attention</summary>\\n-\\n  \\nPerception is our ability to take what we're sensing and focus on it and make sense of it, to explore it, to remember it. So really perceptions are just whichever sensations we happen to be paying attention to at any moment. And you can do this right now. You can experience perception and the difference between perception and sensation very easily. If, for instance, I tell you to pay attention to the contact of your feet, the bottoms of your feet, with whatever surface they happen to be in contact with, maybe it's shoes, maybe it's the floor, if your feet are up maybe it's air. The moment you place your, what we call the spotlight of attention or the spotlight of perception on your feet. You are now perceiving what was happening there, what was being sensed there. The sensation was happening all along however. So while sensation is not negotiable you can't change your receptors unless you adopt some new technology, perception is under the control of your attention.\", metadata={'source': '6'})]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is Deja Vu?\"\n",
    "docs = docsearch.similarity_search(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 4)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts), len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3212.35"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(t) for t in texts])/len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markdown_text.count(\"<details>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**How Your Nervous System Works & Changes | Huberman Lab Podcast #1**\n",
      "\n",
      "[**https://www.youtube.com/watch?v=H-XfCl-HpRM&t=2s**](https://www.youtube.com/watch?v=H-XfCl-HpRM&t=2s)\n",
      "\n",
      "**TRANSCRIPT**\n",
      "\n",
      "<details>\n",
      "<summary>(00:00) Introduction</summary>\n",
      "-\n",
      "    \n",
      "Welcome to the Huberman Lab Podcast where we discuss science and science-based tools for everyday life. (upbeat guitar music) I'm Andrew Huberman and I'm a professor of neurobiology and ophthalmology at Stanford School of Medicine. For today's podcast we're going to talk about the parts list of the nervous system. Now that might sound boring, but these are the bits and pieces that together make up everything about your experience of life, from what you think about to what you feel, what you imagine, and what you accomplish from the day you're born until the day you die. That parts list is really incredible because it has a history associated with it that really provides a window into all sorts of things like engineering, warfare, religion, and philosophy. So I'm going to share with you the parts list that makes up who you are through the lens of some of those other aspects of life and other aspects of the history of the discovery of the nervous system. By the end of this podcast I promise you're going to understand a lot more about how you work and how to apply that knowledge. There's going to be a little bit of story. There's going to be a lot of discussion about the people who made these particular discoveries. There'll be a little bit of technical language. There's no way to avoid that. But at the end you're going to have in hand what will be the equivalent of an entire semester of learning about the nervous system and how you work So a few important points before we get started. I am not a medical doctor. That means I don't prescribe anything. I'm a professor, so sometimes I'll profess things. In fact, I profess a lot of things. We are going to talk about some basic functioning of the nervous system parts and et cetera, but we're also going to talk about how to apply that knowledge. That said, your healthcare, your wellbeing is your responsibility. So anytime we talk about tools please filter it through that responsibility. Talk to a healthcare professional if you're going to explore any new tools or practices and be smart in your pursuit of these new tools. Also wanna emphasize that this podcast and the other things I do on social media are my personal goal of bringing zero cost to consumer information to the general public. It is separate from my role at Stanford University. \n",
      "  \n",
      "In that spirit I really want to thank the sponsors of today's podcast. The first one is Athletic Greens which is an all-in-one drink. It's a greens drink that has vitamins, minerals, probiotics, prebiotics. I've been using Athletic Greens since 2012 so I'm really delighted that they're sponsoring the podcast. The reason I like it is because I like vitamins and minerals, I think they're important to my health and it can be kind of overwhelming to know what to take in that landscape. So by taking one thing that also happens to taste really good I get all the vitamins minerals, et cetera, that I need. There's also a lot of data there now about the importance of the gut microbiome for immune health and for the gut brain access, all these things. And the probiotics and prebiotics are important to me for that reason. If you want to try Athletic Greens you can go to athleticgreens.com/huberman, and put in the code word Huberman at checkout. If you do that they'll send you a year's supply of vitamin D3 and K2. There's a lot in the news lately about the importance of vitamin D3. We can all get vitamin D3 from sunlight but many of us aren't getting enough sunlight. Vitamin D3 has been shown to be relevant to the immune system and the hormone systems, et cetera. So once again that's athleticgreens.com/huberman, enter Huberman at checkout, and you get the year supply of D3 and K2 along with your Athletic Greens. \n",
      "  \n",
      "This podcast is also brought to us by Inside Tracker which is a health monitoring company. It uses blood tests and saliva tests to look at things like DNA and metabolic markers and monitors your hormones, a huge number of different parameters of health that really can only be measured accurately through blood and saliva tests. I use Inside Tracker because I'm a big believer in data. There's a lot of aspects to our biology that can only be accurately measured by way of blood tests and saliva tests. The thing that's really nice about Inside Tracker is that rather than just giving you a bunch of numbers back of the levels of these things in your body, it gives you, through a really simple platform, information about what to do with all those levels of hormones and metabolic markers, et cetera. It also has a feature which is particularly interesting which it measures your inner age, which is more a measure of your biological age as opposed to your chronological age. And all that information is organized so that you can make changes in your nutritional regimes or your exercise regimes and watch how those markers change over time. So if you want to try Inside Tracker you can go to insidetracker.com/huberman and they'll give you 25% off at checkout.\n",
      "=====================================\n",
      "<summary>(05:00) What is the Nervous System</summary>\n",
      "-\n",
      "    \n",
      "So let's talk about the nervous system. The reason I say your nervous system and not your brain is because your brain is actually just one piece of this larger, more important thing, frankly, that we call the nervous system. The nervous system includes your brain and your spinal cord but also all the connections between your brain and your spinal cord and the organs of your body. It also includes, very importantly, all the connections between your organs back to your spinal cord and brain. So the way to think about how you function at every level from the moment you're born until the day you die, everything you think and remember and feel and imagine is that your nervous system is this continuous loop of communication between the brain, spinal cord, and body and body, spinal cord, and brain. In fact, we really can't even separate them. It's one continuous loop. You may have heard of something called a Mobius strip. A Mobius strip is almost like one of these impossible figures that no matter which angle you look at it from you can't tell where it starts and where it ends. And that's really how your nervous system is built. That's the structure that allows you to, for instance, deploy immune cells, to release cells that will go kill infection when you're in the presence of infection. Most people just think about that as a function of the immune system but actually it's your nervous system that tells organs like your spleen to release killer cells that go and hunt down those bacterial and viral invaders and gobble them up. If you have a stomach ache, for instance, sure, you feel that in your stomach, but it's really your nervous system that's causing the stomach ache. The ache aspect of it is a nervous system feature. So when we want to talk about experience or we want to talk about how to change the self in any way, we really need to think about the nervous system first. It is fair to say that the nervous system governs all other biological systems of the body, and it's also influenced by those other biological systems. So if we're talking about the nervous system we need to get a little specific about what we mean. It's not just this big loop of wires. In fact, there's a interesting story about that because at the turn of the sort of 1800s to 1900s, it actually was believed that our nervous system was just one giant cell. But two guys, that names aren't super important, but in fairness to their important discovery, Ramon y Cajal, a Spaniard, Camillo Golgi, an Italian guy, figured out how to label or stain the nervous system in a way that revealed, oh my goodness, we're actually made up of trillions of these little cells, nerve cells that are called neurons. And that's what a neuron is. It's just a nerve cell. They also saw that those nerve cells weren't touching one another. They're actually separated by little gaps. And those little gaps you may have heard of before, they're called synapses. Those synapses are where the chemicals from one neuron are kind of spit out or vomited into. And then the next nerve cell detects those chemicals and then passes electricity down its length to the next nerve cell and so forth. So really the way to think about your body and your thoughts and your mind is that you are a flow of electricity, right? There's nothing mystical about this. You're a flow of electricity between these different nerve cells. And depending on which nerve cells are active you might be lifting your arm or lowering your arm. You might be seeing something and perceiving that it's red or you might be seeing something and perceiving that it's green, all depending on which nerve cells are electrically active at a given moment. The example of perceiving red or perceiving green is a particularly good example because so often our experience of the world makes it seem as if these out these things that are happening outside us are actually happening inside us.\n"
     ]
    }
   ],
   "source": [
    "print(texts[0])\n",
    "print(\"=====================================\")\n",
    "print(texts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/john/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/john/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='How Your Nervous System Works & Changes | Huberman Lab Podcast #1\\n\\nhttps://www.youtube.com/watch?v=H-XfCl-HpRM&t=2s\\n\\nTRANSCRIPT\\n\\nWritten with StackEdit.', metadata={'source': 'md_transcripts/01. How Your Nervous System Works & Changes.md'})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "markdown_path = \"md_transcripts/01. How Your Nervous System Works & Changes.md\"\n",
    "loader = UnstructuredMarkdownLoader(markdown_path)\n",
    "\n",
    "data = loader.load()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "index = VectorstoreIndexCreator().from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chroma collection langchain contains fewer than 4 elements.\n",
      "Chroma collection langchain contains fewer than 3 elements.\n",
      "Chroma collection langchain contains fewer than 2 elements.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' This episode is about how the nervous system works and changes.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is this episode about?\"\n",
    "index.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
